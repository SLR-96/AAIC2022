{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c75a8de",
   "metadata": {},
   "source": [
    "<h2> Team Name: <em>Order of the Phoenix</em> </h2>\n",
    "<br>\n",
    "\n",
    "<div style=\"background:lightblue;\">\n",
    "    <h3> Team Members:</h3>\n",
    "    <br>\n",
    "    <li> Salar Hosseini Shamchi</li>\n",
    "    <li> Mohammad Hosseinzadeh</li>\n",
    "    <li> Ahmad Ahmadi</li>\n",
    "    </div>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647dce3e",
   "metadata": {},
   "source": [
    "Importing all the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a43e1aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MSE\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecayRestarts\n",
    "from sklearn.metrics import r2_score\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b239fbf3",
   "metadata": {},
   "source": [
    "Setting a seed value for consistent results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02a0d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 5\n",
    "seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61061d6",
   "metadata": {},
   "source": [
    "Loading CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45ae8fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = pd.read_csv('./MCI-RD-aaic-UIUF/MCIRD_aaic2021_train.csv', index_col='subscriber_ecid')\n",
    "train_file.insert(train_file.shape[1] - 1, 'data_usage_volume', train_file.pop('data_usage_volume'))\n",
    "\n",
    "week1_file = pd.read_csv('./MCI-RD-aaic-UIUF/MCIRD_aaic2021_test_week1_with_target.csv', index_col='subscriber_ecid')\n",
    "week1_file.insert(week1_file.shape[1] - 1, 'data_usage_volume', week1_file.pop('data_usage_volume'))\n",
    "\n",
    "week2_file = pd.read_csv('./MCI-RD-aaic-UIUF/MCIRD_aaic2021_test_week2.csv', index_col='subscriber_ecid')\n",
    "week2_file.insert(week2_file.shape[1], 'data_usage_volume', np.zeros(week2_file.shape[0]))\n",
    "\n",
    "week3_file = pd.read_csv('./MCI-RD-aaic-UIUF/MCIRD_aaic2021_test_week3.csv', index_col='subscriber_ecid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc6fdc7",
   "metadata": {},
   "source": [
    "Preprocessing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b8893f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "people = np.unique(week3_file.index)\n",
    "total_days = 76\n",
    "x = []\n",
    "y = []\n",
    "for person in people:\n",
    "    person_train = train_file.loc[person]\n",
    "    person_week1 = week1_file.loc[person]\n",
    "    person_data = pd.concat([person_train, person_week1]).drop('day', axis=1).values\n",
    "    data_dim = person_data.shape\n",
    "    for i in range(data_dim[0]):\n",
    "        for j in range(data_dim[1]):\n",
    "            if np.isnan(person_data[i, j]):\n",
    "                person_data[i, j] = np.nanmean(person_data[:, j])\n",
    "\n",
    "    for i in range(person_data.shape[0] - 5):\n",
    "        if i == 0:\n",
    "            sequence = person_data.copy()\n",
    "        else:\n",
    "            sequence = person_data.copy()[:-i]\n",
    "        output = sequence[-1, -1]\n",
    "        sequence[:, -1] = np.roll(sequence[:, -1], 1, axis=0)\n",
    "        pad = np.zeros([total_days - sequence.shape[0], sequence.shape[1]])\n",
    "        sequence = np.vstack((pad, sequence[1:]))\n",
    "        x.append(sequence)\n",
    "        y.append(output)\n",
    "\n",
    "x = np.asarray(x, dtype=np.float64)\n",
    "y = np.asarray(y, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfa37ab",
   "metadata": {},
   "source": [
    "Splitting the data to train and validation sets, and normalizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a47fb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./My Model'):\n",
    "    shutil.rmtree('./My Model')\n",
    "os.makedirs('./My Model')\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.1, random_state=7)\n",
    "\n",
    "np.save('./My Model/x_train.npy', x_train)\n",
    "np.save('./My Model/x_val.npy', x_val)\n",
    "np.save('./My Model/y_train.npy', y_train)\n",
    "np.save('./My Model/y_val.npy', y_val)\n",
    "\n",
    "x_min = x_train.min(axis=(0, 1))\n",
    "x_max = x_train.max(axis=(0, 1))\n",
    "x_indices = np.where(x_min == x_max)[0]\n",
    "for ind in x_indices:\n",
    "    x_max[ind] += 1\n",
    "\n",
    "np.save('./My Model/x_min.npy', x_min)\n",
    "np.save('./My Model/x_max.npy', x_max)\n",
    "\n",
    "x_train = (x_train - x_min) / (x_max - x_min)\n",
    "x_val = (x_val - x_min) / (x_max - x_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a4e3d9",
   "metadata": {},
   "source": [
    "Building the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f622a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None, 32)]        0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, None, 16)          3136      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,265\n",
      "Trainable params: 5,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp_layer = Input(shape=(None, x_train.shape[2]))\n",
    "layer = LSTM(16, return_sequences=True)(inp_layer)\n",
    "layer = LSTM(16, return_sequences=False)(layer)\n",
    "out_layer = Dense(1, activation='linear')(layer)\n",
    "\n",
    "my_model = Model(inp_layer, out_layer)\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fa2d83",
   "metadata": {},
   "source": [
    "Training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65ad0add",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "12/12 [==============================] - 8s 154ms/step - loss: 9.7289 - val_loss: 46.5738\n",
      "Epoch 2/2000\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 8.9460 - val_loss: 45.9471\n",
      "Epoch 3/2000\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 8.6825 - val_loss: 45.5183\n",
      "Epoch 4/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 8.5250 - val_loss: 45.4448\n",
      "Epoch 5/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 8.4257 - val_loss: 45.4299\n",
      "Epoch 6/2000\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 8.2056 - val_loss: 44.9222\n",
      "Epoch 7/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 7.7395 - val_loss: 44.7318\n",
      "Epoch 8/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 7.4325 - val_loss: 44.3667\n",
      "Epoch 9/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 7.0847 - val_loss: 43.9860\n",
      "Epoch 10/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 6.9273 - val_loss: 43.9581\n",
      "Epoch 11/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 6.8518 - val_loss: 43.8894\n",
      "Epoch 12/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 6.8193 - val_loss: 44.0680\n",
      "Epoch 13/2000\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 6.6482 - val_loss: 43.3518\n",
      "Epoch 14/2000\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 6.4459 - val_loss: 43.1104\n",
      "Epoch 15/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 6.3989 - val_loss: 42.8286\n",
      "Epoch 16/2000\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 6.1968 - val_loss: 42.8068\n",
      "Epoch 17/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 6.1530 - val_loss: 42.5292\n",
      "Epoch 18/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 6.0237 - val_loss: 42.4252\n",
      "Epoch 19/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.9238 - val_loss: 42.2989\n",
      "Epoch 20/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 5.8652 - val_loss: 42.2061\n",
      "Epoch 21/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 5.8091 - val_loss: 42.1606\n",
      "Epoch 22/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.7840 - val_loss: 42.0880\n",
      "Epoch 23/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 5.7654 - val_loss: 42.1043\n",
      "Epoch 24/2000\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 5.7583 - val_loss: 42.0808\n",
      "Epoch 25/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.7548 - val_loss: 42.0792\n",
      "Epoch 26/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 5.8813 - val_loss: 42.2231\n",
      "Epoch 27/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 6.0130 - val_loss: 41.7597\n",
      "Epoch 28/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 5.8719 - val_loss: 41.9729\n",
      "Epoch 29/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 5.7330 - val_loss: 41.4490\n",
      "Epoch 30/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.6119 - val_loss: 41.4265\n",
      "Epoch 31/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 5.5499 - val_loss: 41.3371\n",
      "Epoch 32/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 5.5200 - val_loss: 41.1541\n",
      "Epoch 33/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.4938 - val_loss: 41.0669\n",
      "Epoch 34/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.5139 - val_loss: 40.9022\n",
      "Epoch 35/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 5.4752 - val_loss: 40.7841\n",
      "Epoch 36/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.4496 - val_loss: 40.6668\n",
      "Epoch 37/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 5.4159 - val_loss: 40.6978\n",
      "Epoch 38/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.3850 - val_loss: 40.5259\n",
      "Epoch 39/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.3647 - val_loss: 40.4324\n",
      "Epoch 40/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 5.3465 - val_loss: 40.3514\n",
      "Epoch 41/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.3294 - val_loss: 40.2562\n",
      "Epoch 42/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 5.3198 - val_loss: 40.1314\n",
      "Epoch 43/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.3017 - val_loss: 40.0869\n",
      "Epoch 44/2000\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 5.2957 - val_loss: 40.0637\n",
      "Epoch 45/2000\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 5.2863 - val_loss: 40.0198\n",
      "Epoch 46/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 5.2832 - val_loss: 40.0484\n",
      "Epoch 47/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 5.2747 - val_loss: 39.9940\n",
      "Epoch 48/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.2726 - val_loss: 39.9921\n",
      "Epoch 49/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.2692 - val_loss: 39.9911\n",
      "Epoch 50/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 5.2680 - val_loss: 39.9931\n",
      "Epoch 51/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.2668 - val_loss: 39.9906\n",
      "Epoch 52/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 5.2704 - val_loss: 39.9949\n",
      "Epoch 53/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 5.3307 - val_loss: 39.9494\n",
      "Epoch 54/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.2637 - val_loss: 39.6151\n",
      "Epoch 55/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 5.2955 - val_loss: 39.9620\n",
      "Epoch 56/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 5.4751 - val_loss: 39.6500\n",
      "Epoch 57/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.2224 - val_loss: 39.4197\n",
      "Epoch 58/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.1942 - val_loss: 39.2270\n",
      "Epoch 59/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 5.1870 - val_loss: 39.9427\n",
      "Epoch 60/2000\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 5.6318 - val_loss: 39.0431\n",
      "Epoch 61/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 5.2398 - val_loss: 39.2048\n",
      "Epoch 62/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 5.1455 - val_loss: 39.1574\n",
      "Epoch 63/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 5.1230 - val_loss: 39.1059\n",
      "Epoch 64/2000\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 5.0772 - val_loss: 38.9611\n",
      "Epoch 65/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.0675 - val_loss: 38.9154\n",
      "Epoch 66/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.0594 - val_loss: 38.8385\n",
      "Epoch 67/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 5.0234 - val_loss: 38.9396\n",
      "Epoch 68/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 5.1261 - val_loss: 39.2154\n",
      "Epoch 69/2000\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 5.0522 - val_loss: 38.8031\n",
      "Epoch 70/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 5.0094 - val_loss: 38.7519\n",
      "Epoch 71/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.9753 - val_loss: 38.7830\n",
      "Epoch 72/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.9681 - val_loss: 38.7145\n",
      "Epoch 73/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 4.9442 - val_loss: 38.6545\n",
      "Epoch 74/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.9406 - val_loss: 38.8276\n",
      "Epoch 75/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 5.1943 - val_loss: 39.2352\n",
      "Epoch 76/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 5.2464 - val_loss: 38.6229\n",
      "Epoch 77/2000\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 5.0688 - val_loss: 38.4399\n",
      "Epoch 78/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 4.9429 - val_loss: 38.6246\n",
      "Epoch 79/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.9036 - val_loss: 38.4709\n",
      "Epoch 80/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 29ms/step - loss: 4.8978 - val_loss: 38.4710\n",
      "Epoch 81/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.8736 - val_loss: 38.4843\n",
      "Epoch 82/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 4.8693 - val_loss: 38.3034\n",
      "Epoch 83/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.8477 - val_loss: 38.4095\n",
      "Epoch 84/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.8422 - val_loss: 38.3695\n",
      "Epoch 85/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.8290 - val_loss: 38.4034\n",
      "Epoch 86/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.8403 - val_loss: 38.2957\n",
      "Epoch 87/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 4.8389 - val_loss: 38.3934\n",
      "Epoch 88/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.8239 - val_loss: 38.3509\n",
      "Epoch 89/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.8123 - val_loss: 38.2415\n",
      "Epoch 90/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.8054 - val_loss: 38.3045\n",
      "Epoch 91/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.7980 - val_loss: 38.2584\n",
      "Epoch 92/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.7895 - val_loss: 38.2336\n",
      "Epoch 93/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.7865 - val_loss: 38.2592\n",
      "Epoch 94/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.7780 - val_loss: 38.2232\n",
      "Epoch 95/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.7765 - val_loss: 38.2103\n",
      "Epoch 96/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 4.7760 - val_loss: 38.1914\n",
      "Epoch 97/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.7695 - val_loss: 38.2083\n",
      "Epoch 98/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.7700 - val_loss: 38.1897\n",
      "Epoch 99/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.7664 - val_loss: 38.1990\n",
      "Epoch 100/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.7649 - val_loss: 38.1999\n",
      "Epoch 101/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.7638 - val_loss: 38.1992\n",
      "Epoch 102/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.7636 - val_loss: 38.1935\n",
      "Epoch 103/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.7628 - val_loss: 38.1921\n",
      "Epoch 104/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.7626 - val_loss: 38.1917\n",
      "Epoch 105/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.7625 - val_loss: 38.1917\n",
      "Epoch 106/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.9897 - val_loss: 38.2237\n",
      "Epoch 107/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.9469 - val_loss: 38.0238\n",
      "Epoch 108/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.8784 - val_loss: 38.0686\n",
      "Epoch 109/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.7870 - val_loss: 38.0410\n",
      "Epoch 110/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.7957 - val_loss: 37.9499\n",
      "Epoch 111/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.7792 - val_loss: 37.7698\n",
      "Epoch 112/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.7716 - val_loss: 37.9004\n",
      "Epoch 113/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.7941 - val_loss: 37.8754\n",
      "Epoch 114/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.9266 - val_loss: 38.0198\n",
      "Epoch 115/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.8250 - val_loss: 37.9450\n",
      "Epoch 116/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.7874 - val_loss: 37.7110\n",
      "Epoch 117/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.7469 - val_loss: 37.6195\n",
      "Epoch 118/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.7709 - val_loss: 37.9943\n",
      "Epoch 119/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.9166 - val_loss: 38.1746\n",
      "Epoch 120/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.7542 - val_loss: 37.9726\n",
      "Epoch 121/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.8198 - val_loss: 37.8467\n",
      "Epoch 122/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.8513 - val_loss: 37.8793\n",
      "Epoch 123/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 5.0509 - val_loss: 38.8200\n",
      "Epoch 124/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 6.1855 - val_loss: 38.5099\n",
      "Epoch 125/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 5.1534 - val_loss: 38.0020\n",
      "Epoch 126/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.8878 - val_loss: 38.1395\n",
      "Epoch 127/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.7588 - val_loss: 37.9574\n",
      "Epoch 128/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.7035 - val_loss: 38.0000\n",
      "Epoch 129/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.6462 - val_loss: 37.8562\n",
      "Epoch 130/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.6419 - val_loss: 37.9596\n",
      "Epoch 131/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.6192 - val_loss: 37.9601\n",
      "Epoch 132/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.5931 - val_loss: 37.9217\n",
      "Epoch 133/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.5949 - val_loss: 37.7561\n",
      "Epoch 134/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.5657 - val_loss: 37.7044\n",
      "Epoch 135/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.5602 - val_loss: 37.6763\n",
      "Epoch 136/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.5478 - val_loss: 37.6701\n",
      "Epoch 137/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.5586 - val_loss: 37.2955\n",
      "Epoch 138/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.5327 - val_loss: 37.6885\n",
      "Epoch 139/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.5038 - val_loss: 37.6505\n",
      "Epoch 140/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.5086 - val_loss: 37.7828\n",
      "Epoch 141/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.4892 - val_loss: 37.4905\n",
      "Epoch 142/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.4840 - val_loss: 37.5403\n",
      "Epoch 143/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.4652 - val_loss: 37.4785\n",
      "Epoch 144/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.4766 - val_loss: 37.5864\n",
      "Epoch 145/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.4637 - val_loss: 37.6332\n",
      "Epoch 146/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.4573 - val_loss: 37.6205\n",
      "Epoch 147/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.4449 - val_loss: 37.3481\n",
      "Epoch 148/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.4360 - val_loss: 37.3909\n",
      "Epoch 149/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.4238 - val_loss: 37.4576\n",
      "Epoch 150/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.4520 - val_loss: 37.4981\n",
      "Epoch 151/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.4117 - val_loss: 37.4459\n",
      "Epoch 152/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.3982 - val_loss: 37.3725\n",
      "Epoch 153/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.4285 - val_loss: 37.5232\n",
      "Epoch 154/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.4087 - val_loss: 37.5987\n",
      "Epoch 155/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.4147 - val_loss: 37.3070\n",
      "Epoch 156/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.3848 - val_loss: 37.5530\n",
      "Epoch 157/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.3804 - val_loss: 37.5541\n",
      "Epoch 158/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.3752 - val_loss: 37.4152\n",
      "Epoch 159/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 29ms/step - loss: 4.3551 - val_loss: 37.3464\n",
      "Epoch 160/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.3529 - val_loss: 37.2900\n",
      "Epoch 161/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.3416 - val_loss: 37.3105\n",
      "Epoch 162/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.3374 - val_loss: 37.3260\n",
      "Epoch 163/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.3226 - val_loss: 37.1365\n",
      "Epoch 164/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.3148 - val_loss: 37.1704\n",
      "Epoch 165/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.3109 - val_loss: 37.1395\n",
      "Epoch 166/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.3083 - val_loss: 37.2492\n",
      "Epoch 167/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.3098 - val_loss: 37.1426\n",
      "Epoch 168/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.2983 - val_loss: 37.1940\n",
      "Epoch 169/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.3019 - val_loss: 37.1746\n",
      "Epoch 170/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.2933 - val_loss: 37.1907\n",
      "Epoch 171/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.2806 - val_loss: 37.1866\n",
      "Epoch 172/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.2776 - val_loss: 37.1367\n",
      "Epoch 173/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.2759 - val_loss: 37.1814\n",
      "Epoch 174/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 4.2789 - val_loss: 37.1581\n",
      "Epoch 175/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.2630 - val_loss: 37.1337\n",
      "Epoch 176/2000\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 4.2635 - val_loss: 37.1138\n",
      "Epoch 177/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.2594 - val_loss: 37.1625\n",
      "Epoch 178/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.2582 - val_loss: 37.1190\n",
      "Epoch 179/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 4.2489 - val_loss: 37.1104\n",
      "Epoch 180/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 4.2427 - val_loss: 37.0774\n",
      "Epoch 181/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.2418 - val_loss: 37.0969\n",
      "Epoch 182/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.2428 - val_loss: 37.1096\n",
      "Epoch 183/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 4.2414 - val_loss: 37.0831\n",
      "Epoch 184/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.2316 - val_loss: 37.0912\n",
      "Epoch 185/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 4.2300 - val_loss: 37.0842\n",
      "Epoch 186/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.2281 - val_loss: 37.0430\n",
      "Epoch 187/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.2241 - val_loss: 37.0504\n",
      "Epoch 188/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.2197 - val_loss: 37.0324\n",
      "Epoch 189/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.2209 - val_loss: 37.0429\n",
      "Epoch 190/2000\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 4.2183 - val_loss: 36.9940\n",
      "Epoch 191/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 4.2163 - val_loss: 37.0016\n",
      "Epoch 192/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.2118 - val_loss: 37.0001\n",
      "Epoch 193/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.2111 - val_loss: 37.0065\n",
      "Epoch 194/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.2125 - val_loss: 37.0134\n",
      "Epoch 195/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.2067 - val_loss: 36.9900\n",
      "Epoch 196/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.2068 - val_loss: 36.9948\n",
      "Epoch 197/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.2044 - val_loss: 36.9889\n",
      "Epoch 198/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 4.2045 - val_loss: 36.9875\n",
      "Epoch 199/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.2031 - val_loss: 36.9852\n",
      "Epoch 200/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.2019 - val_loss: 36.9852\n",
      "Epoch 201/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.2018 - val_loss: 36.9873\n",
      "Epoch 202/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.2007 - val_loss: 36.9873\n",
      "Epoch 203/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.2001 - val_loss: 36.9854\n",
      "Epoch 204/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 4.1993 - val_loss: 36.9804\n",
      "Epoch 205/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.1993 - val_loss: 36.9785\n",
      "Epoch 206/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.1988 - val_loss: 36.9813\n",
      "Epoch 207/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.1985 - val_loss: 36.9804\n",
      "Epoch 208/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.1983 - val_loss: 36.9804\n",
      "Epoch 209/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.1982 - val_loss: 36.9806\n",
      "Epoch 210/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.1981 - val_loss: 36.9808\n",
      "Epoch 211/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 4.1980 - val_loss: 36.9808\n",
      "Epoch 212/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.2007 - val_loss: 36.9612\n",
      "Epoch 213/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.2754 - val_loss: 37.0485\n",
      "Epoch 214/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.3492 - val_loss: 37.3369\n",
      "Epoch 215/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.3007 - val_loss: 37.3988\n",
      "Epoch 216/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.6410 - val_loss: 37.2366\n",
      "Epoch 217/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.4766 - val_loss: 37.3683\n",
      "Epoch 218/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.3897 - val_loss: 37.4005\n",
      "Epoch 219/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.4045 - val_loss: 37.4200\n",
      "Epoch 220/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.3294 - val_loss: 37.2791\n",
      "Epoch 221/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.2515 - val_loss: 37.2545\n",
      "Epoch 222/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.2870 - val_loss: 37.1817\n",
      "Epoch 223/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 4.1991 - val_loss: 37.1495\n",
      "Epoch 224/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.2450 - val_loss: 37.1337\n",
      "Epoch 225/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.3913 - val_loss: 37.2722\n",
      "Epoch 226/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.2297 - val_loss: 37.5235\n",
      "Epoch 227/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.1438 - val_loss: 37.5134\n",
      "Epoch 228/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.1620 - val_loss: 37.3799\n",
      "Epoch 229/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 4.1820 - val_loss: 36.9487\n",
      "Epoch 230/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.1933 - val_loss: 37.3342\n",
      "Epoch 231/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.1801 - val_loss: 37.1981\n",
      "Epoch 232/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.1395 - val_loss: 37.3337\n",
      "Epoch 233/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 4.0943 - val_loss: 37.0048\n",
      "Epoch 234/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.0940 - val_loss: 37.0471\n",
      "Epoch 235/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.0871 - val_loss: 36.9457\n",
      "Epoch 236/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 4.0318 - val_loss: 37.0577\n",
      "Epoch 237/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.0478 - val_loss: 36.9405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 4.0245 - val_loss: 36.8214\n",
      "Epoch 239/2000\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 4.0793 - val_loss: 36.8010\n",
      "Epoch 240/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.0115 - val_loss: 37.1660\n",
      "Epoch 241/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.9914 - val_loss: 36.9013\n",
      "Epoch 242/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.0325 - val_loss: 37.0507\n",
      "Epoch 243/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.0033 - val_loss: 36.8205\n",
      "Epoch 244/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 3.9620 - val_loss: 36.7749\n",
      "Epoch 245/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.9486 - val_loss: 36.9120\n",
      "Epoch 246/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.9505 - val_loss: 36.9020\n",
      "Epoch 247/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.0357 - val_loss: 36.5374\n",
      "Epoch 248/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.1424 - val_loss: 36.6756\n",
      "Epoch 249/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 4.0520 - val_loss: 37.1091\n",
      "Epoch 250/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.9417 - val_loss: 37.1094\n",
      "Epoch 251/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.9839 - val_loss: 36.8903\n",
      "Epoch 252/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.9128 - val_loss: 36.8155\n",
      "Epoch 253/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.9256 - val_loss: 36.8643\n",
      "Epoch 254/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.9171 - val_loss: 36.7006\n",
      "Epoch 255/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.8895 - val_loss: 36.7677\n",
      "Epoch 256/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.9099 - val_loss: 36.9162\n",
      "Epoch 257/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.9582 - val_loss: 36.4619\n",
      "Epoch 258/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.9044 - val_loss: 36.7078\n",
      "Epoch 259/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.8944 - val_loss: 36.7340\n",
      "Epoch 260/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.8686 - val_loss: 36.8134\n",
      "Epoch 261/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.8464 - val_loss: 36.7351\n",
      "Epoch 262/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.8727 - val_loss: 36.5770\n",
      "Epoch 263/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.8398 - val_loss: 36.6730\n",
      "Epoch 264/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.8201 - val_loss: 36.6913\n",
      "Epoch 265/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.8541 - val_loss: 36.7109\n",
      "Epoch 266/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.8483 - val_loss: 36.5744\n",
      "Epoch 267/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.8358 - val_loss: 36.7540\n",
      "Epoch 268/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.8496 - val_loss: 36.6777\n",
      "Epoch 269/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.8667 - val_loss: 36.6425\n",
      "Epoch 270/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.8298 - val_loss: 36.5470\n",
      "Epoch 271/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.7855 - val_loss: 36.4918\n",
      "Epoch 272/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.7824 - val_loss: 36.4929\n",
      "Epoch 273/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.8136 - val_loss: 36.5599\n",
      "Epoch 274/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 3.7599 - val_loss: 36.2709\n",
      "Epoch 275/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.7995 - val_loss: 36.5148\n",
      "Epoch 276/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.7930 - val_loss: 36.3649\n",
      "Epoch 277/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.7449 - val_loss: 36.5142\n",
      "Epoch 278/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.7433 - val_loss: 36.4590\n",
      "Epoch 279/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.7583 - val_loss: 36.2725\n",
      "Epoch 280/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.7937 - val_loss: 36.2883\n",
      "Epoch 281/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.7550 - val_loss: 36.3854\n",
      "Epoch 282/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.7176 - val_loss: 36.3636\n",
      "Epoch 283/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.7214 - val_loss: 36.3912\n",
      "Epoch 284/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.7247 - val_loss: 36.3990\n",
      "Epoch 285/2000\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 3.7238 - val_loss: 36.2447\n",
      "Epoch 286/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.6981 - val_loss: 36.3847\n",
      "Epoch 287/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.6980 - val_loss: 36.3164\n",
      "Epoch 288/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.7042 - val_loss: 36.3449\n",
      "Epoch 289/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.6717 - val_loss: 36.3134\n",
      "Epoch 290/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.6776 - val_loss: 36.3004\n",
      "Epoch 291/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.6911 - val_loss: 36.3971\n",
      "Epoch 292/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.6948 - val_loss: 36.3158\n",
      "Epoch 293/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.6759 - val_loss: 36.3796\n",
      "Epoch 294/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.6356 - val_loss: 36.3035\n",
      "Epoch 295/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.6359 - val_loss: 36.3824\n",
      "Epoch 296/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.6533 - val_loss: 36.1903\n",
      "Epoch 297/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.6687 - val_loss: 36.2029\n",
      "Epoch 298/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 3.6431 - val_loss: 36.1229\n",
      "Epoch 299/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.7196 - val_loss: 36.5213\n",
      "Epoch 300/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.7204 - val_loss: 36.2921\n",
      "Epoch 301/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.6399 - val_loss: 36.3131\n",
      "Epoch 302/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.6093 - val_loss: 36.1862\n",
      "Epoch 303/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.5990 - val_loss: 36.3318\n",
      "Epoch 304/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.5955 - val_loss: 36.1063\n",
      "Epoch 305/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.5766 - val_loss: 36.1232\n",
      "Epoch 306/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.6045 - val_loss: 36.1772\n",
      "Epoch 307/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.6120 - val_loss: 36.0907\n",
      "Epoch 308/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.5966 - val_loss: 36.1933\n",
      "Epoch 309/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.5681 - val_loss: 36.1003\n",
      "Epoch 310/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.5543 - val_loss: 36.2627\n",
      "Epoch 311/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.5521 - val_loss: 36.2316\n",
      "Epoch 312/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.5682 - val_loss: 36.1703\n",
      "Epoch 313/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.5489 - val_loss: 36.3165\n",
      "Epoch 314/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.5524 - val_loss: 36.1525\n",
      "Epoch 315/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.5332 - val_loss: 36.1258\n",
      "Epoch 316/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.5513 - val_loss: 36.1008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.5503 - val_loss: 36.1822\n",
      "Epoch 318/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.5274 - val_loss: 36.1626\n",
      "Epoch 319/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.5296 - val_loss: 36.2038\n",
      "Epoch 320/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.5416 - val_loss: 36.1260\n",
      "Epoch 321/2000\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 3.5267 - val_loss: 36.0898\n",
      "Epoch 322/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.5241 - val_loss: 36.1323\n",
      "Epoch 323/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.5023 - val_loss: 36.0949\n",
      "Epoch 324/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.5152 - val_loss: 36.0868\n",
      "Epoch 325/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.5247 - val_loss: 36.2068\n",
      "Epoch 326/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.5269 - val_loss: 36.1138\n",
      "Epoch 327/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4958 - val_loss: 36.1112\n",
      "Epoch 328/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4995 - val_loss: 36.0927\n",
      "Epoch 329/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.5224 - val_loss: 36.1169\n",
      "Epoch 330/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.4875 - val_loss: 36.1656\n",
      "Epoch 331/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4810 - val_loss: 36.1442\n",
      "Epoch 332/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.4807 - val_loss: 36.0469\n",
      "Epoch 333/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4849 - val_loss: 36.0561\n",
      "Epoch 334/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4876 - val_loss: 36.0552\n",
      "Epoch 335/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4701 - val_loss: 36.0754\n",
      "Epoch 336/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4688 - val_loss: 36.1763\n",
      "Epoch 337/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4617 - val_loss: 36.0608\n",
      "Epoch 338/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4624 - val_loss: 36.1105\n",
      "Epoch 339/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4666 - val_loss: 36.0587\n",
      "Epoch 340/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4716 - val_loss: 36.1744\n",
      "Epoch 341/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4835 - val_loss: 36.0661\n",
      "Epoch 342/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4555 - val_loss: 36.0857\n",
      "Epoch 343/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4522 - val_loss: 36.0665\n",
      "Epoch 344/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4426 - val_loss: 36.0788\n",
      "Epoch 345/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4407 - val_loss: 36.1213\n",
      "Epoch 346/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4351 - val_loss: 36.1365\n",
      "Epoch 347/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.4418 - val_loss: 36.0353\n",
      "Epoch 348/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4417 - val_loss: 36.0661\n",
      "Epoch 349/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4413 - val_loss: 36.0698\n",
      "Epoch 350/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4314 - val_loss: 36.0845\n",
      "Epoch 351/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4286 - val_loss: 36.0816\n",
      "Epoch 352/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4289 - val_loss: 36.0671\n",
      "Epoch 353/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4332 - val_loss: 36.1120\n",
      "Epoch 354/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4414 - val_loss: 36.0967\n",
      "Epoch 355/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 3.4329 - val_loss: 36.0316\n",
      "Epoch 356/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4158 - val_loss: 36.0638\n",
      "Epoch 357/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.4221 - val_loss: 36.0943\n",
      "Epoch 358/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4114 - val_loss: 36.0614\n",
      "Epoch 359/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4183 - val_loss: 36.0568\n",
      "Epoch 360/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.4115 - val_loss: 36.0933\n",
      "Epoch 361/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4144 - val_loss: 36.0879\n",
      "Epoch 362/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4210 - val_loss: 36.0621\n",
      "Epoch 363/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4101 - val_loss: 36.0557\n",
      "Epoch 364/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4043 - val_loss: 36.0729\n",
      "Epoch 365/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4020 - val_loss: 36.0590\n",
      "Epoch 366/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4022 - val_loss: 36.0434\n",
      "Epoch 367/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3990 - val_loss: 36.0342\n",
      "Epoch 368/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.3972 - val_loss: 35.9830\n",
      "Epoch 369/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3960 - val_loss: 35.9956\n",
      "Epoch 370/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3974 - val_loss: 36.0180\n",
      "Epoch 371/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3958 - val_loss: 36.0150\n",
      "Epoch 372/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3973 - val_loss: 36.0737\n",
      "Epoch 373/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3923 - val_loss: 36.0226\n",
      "Epoch 374/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3933 - val_loss: 36.0290\n",
      "Epoch 375/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3857 - val_loss: 35.9997\n",
      "Epoch 376/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3879 - val_loss: 36.0392\n",
      "Epoch 377/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3826 - val_loss: 36.0329\n",
      "Epoch 378/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3859 - val_loss: 36.0203\n",
      "Epoch 379/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3867 - val_loss: 36.0416\n",
      "Epoch 380/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3852 - val_loss: 36.0408\n",
      "Epoch 381/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3794 - val_loss: 36.0563\n",
      "Epoch 382/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3788 - val_loss: 36.0414\n",
      "Epoch 383/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3780 - val_loss: 36.0193\n",
      "Epoch 384/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3769 - val_loss: 36.0355\n",
      "Epoch 385/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3770 - val_loss: 36.0292\n",
      "Epoch 386/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3777 - val_loss: 36.0340\n",
      "Epoch 387/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3735 - val_loss: 36.0255\n",
      "Epoch 388/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3748 - val_loss: 36.0483\n",
      "Epoch 389/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3742 - val_loss: 36.0516\n",
      "Epoch 390/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3735 - val_loss: 36.0419\n",
      "Epoch 391/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3709 - val_loss: 36.0409\n",
      "Epoch 392/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3722 - val_loss: 36.0410\n",
      "Epoch 393/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3737 - val_loss: 36.0231\n",
      "Epoch 394/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.3703 - val_loss: 36.0279\n",
      "Epoch 395/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3694 - val_loss: 36.0257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3675 - val_loss: 36.0131\n",
      "Epoch 397/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3676 - val_loss: 36.0268\n",
      "Epoch 398/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3668 - val_loss: 36.0202\n",
      "Epoch 399/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3678 - val_loss: 36.0193\n",
      "Epoch 400/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.3673 - val_loss: 36.0154\n",
      "Epoch 401/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3669 - val_loss: 36.0261\n",
      "Epoch 402/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3656 - val_loss: 36.0296\n",
      "Epoch 403/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3652 - val_loss: 36.0309\n",
      "Epoch 404/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3646 - val_loss: 36.0271\n",
      "Epoch 405/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3649 - val_loss: 36.0287\n",
      "Epoch 406/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3647 - val_loss: 36.0308\n",
      "Epoch 407/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3643 - val_loss: 36.0312\n",
      "Epoch 408/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3643 - val_loss: 36.0377\n",
      "Epoch 409/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3657 - val_loss: 36.0362\n",
      "Epoch 410/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3633 - val_loss: 36.0344\n",
      "Epoch 411/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3631 - val_loss: 36.0332\n",
      "Epoch 412/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3635 - val_loss: 36.0314\n",
      "Epoch 413/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 3.3630 - val_loss: 36.0341\n",
      "Epoch 414/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3626 - val_loss: 36.0321\n",
      "Epoch 415/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3625 - val_loss: 36.0331\n",
      "Epoch 416/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3625 - val_loss: 36.0321\n",
      "Epoch 417/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3625 - val_loss: 36.0321\n",
      "Epoch 418/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3622 - val_loss: 36.0325\n",
      "Epoch 419/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3622 - val_loss: 36.0327\n",
      "Epoch 420/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3622 - val_loss: 36.0332\n",
      "Epoch 421/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3621 - val_loss: 36.0331\n",
      "Epoch 422/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.3620 - val_loss: 36.0331\n",
      "Epoch 423/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3620 - val_loss: 36.0331\n",
      "Epoch 424/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3620 - val_loss: 36.0331\n",
      "Epoch 425/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3620 - val_loss: 36.0331\n",
      "Epoch 426/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4234 - val_loss: 36.0246\n",
      "Epoch 427/2000\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.4640 - val_loss: 35.9501\n",
      "Epoch 428/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4523 - val_loss: 36.2581\n",
      "Epoch 429/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.5225 - val_loss: 36.2045\n",
      "Epoch 430/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4927 - val_loss: 36.1081\n",
      "Epoch 431/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.5281 - val_loss: 36.2010\n",
      "Epoch 432/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4747 - val_loss: 36.1461\n",
      "Epoch 433/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.5812 - val_loss: 36.1471\n",
      "Epoch 434/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.5899 - val_loss: 36.1790\n",
      "Epoch 435/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.5267 - val_loss: 35.9719\n",
      "Epoch 436/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4475 - val_loss: 35.9681\n",
      "Epoch 437/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 3.4443 - val_loss: 35.8176\n",
      "Epoch 438/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.4178 - val_loss: 35.8441\n",
      "Epoch 439/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 3.4351 - val_loss: 35.7666\n",
      "Epoch 440/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4641 - val_loss: 36.0893\n",
      "Epoch 441/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.7645 - val_loss: 36.0673\n",
      "Epoch 442/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4640 - val_loss: 35.9918\n",
      "Epoch 443/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4506 - val_loss: 35.8339\n",
      "Epoch 444/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3981 - val_loss: 36.0215\n",
      "Epoch 445/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4223 - val_loss: 35.8097\n",
      "Epoch 446/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.4224 - val_loss: 35.7218\n",
      "Epoch 447/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 3.4178 - val_loss: 35.6699\n",
      "Epoch 448/2000\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 3.4112 - val_loss: 35.5759\n",
      "Epoch 449/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.3949 - val_loss: 35.9423\n",
      "Epoch 450/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3752 - val_loss: 35.9264\n",
      "Epoch 451/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3723 - val_loss: 35.8188\n",
      "Epoch 452/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3622 - val_loss: 35.6214\n",
      "Epoch 453/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3401 - val_loss: 36.1051\n",
      "Epoch 454/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4104 - val_loss: 35.9418\n",
      "Epoch 455/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.4021 - val_loss: 35.5775\n",
      "Epoch 456/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3907 - val_loss: 35.9566\n",
      "Epoch 457/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3648 - val_loss: 35.9388\n",
      "Epoch 458/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3350 - val_loss: 35.8391\n",
      "Epoch 459/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3263 - val_loss: 35.7942\n",
      "Epoch 460/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3056 - val_loss: 35.7200\n",
      "Epoch 461/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.2977 - val_loss: 35.9676\n",
      "Epoch 462/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.2976 - val_loss: 35.7784\n",
      "Epoch 463/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3094 - val_loss: 35.8967\n",
      "Epoch 464/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3261 - val_loss: 35.8692\n",
      "Epoch 465/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3052 - val_loss: 35.7776\n",
      "Epoch 466/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3030 - val_loss: 35.8119\n",
      "Epoch 467/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3011 - val_loss: 35.7093\n",
      "Epoch 468/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3251 - val_loss: 35.8244\n",
      "Epoch 469/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3189 - val_loss: 35.6762\n",
      "Epoch 470/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3191 - val_loss: 35.6761\n",
      "Epoch 471/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 3.3966 - val_loss: 35.5672\n",
      "Epoch 472/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3239 - val_loss: 35.7690\n",
      "Epoch 473/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.2766 - val_loss: 35.9394\n",
      "Epoch 474/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.2547 - val_loss: 35.5048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.2538 - val_loss: 35.6629\n",
      "Epoch 476/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.2662 - val_loss: 36.0813\n",
      "Epoch 477/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.2613 - val_loss: 35.7832\n",
      "Epoch 478/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.3009 - val_loss: 35.7423\n",
      "Epoch 479/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.3115 - val_loss: 35.9735\n",
      "Epoch 480/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.2618 - val_loss: 35.8911\n",
      "Epoch 481/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.2671 - val_loss: 35.7686\n",
      "Epoch 482/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.2510 - val_loss: 35.9189\n",
      "Epoch 483/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.2434 - val_loss: 35.7348\n",
      "Epoch 484/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.2666 - val_loss: 35.7656\n",
      "Epoch 485/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.2714 - val_loss: 35.8383\n",
      "Epoch 486/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.2357 - val_loss: 35.7362\n",
      "Epoch 487/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.2219 - val_loss: 35.6676\n",
      "Epoch 488/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.2449 - val_loss: 36.0514\n",
      "Epoch 489/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.2294 - val_loss: 35.6746\n",
      "Epoch 490/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.2573 - val_loss: 35.8286\n",
      "Epoch 491/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.2424 - val_loss: 35.6342\n",
      "Epoch 492/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.2271 - val_loss: 35.9489\n",
      "Epoch 493/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.2054 - val_loss: 35.6566\n",
      "Epoch 494/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.2146 - val_loss: 35.7094\n",
      "Epoch 495/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.2460 - val_loss: 35.8087\n",
      "Epoch 496/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.2244 - val_loss: 35.8243\n",
      "Epoch 497/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.2155 - val_loss: 35.7082\n",
      "Epoch 498/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.2354 - val_loss: 35.7114\n",
      "Epoch 499/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1838 - val_loss: 35.7715\n",
      "Epoch 500/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.2013 - val_loss: 35.4707\n",
      "Epoch 501/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.2075 - val_loss: 35.8420\n",
      "Epoch 502/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.2412 - val_loss: 35.9471\n",
      "Epoch 503/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.1866 - val_loss: 35.4448\n",
      "Epoch 504/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1590 - val_loss: 35.5249\n",
      "Epoch 505/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.1851 - val_loss: 35.8349\n",
      "Epoch 506/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.2090 - val_loss: 35.7059\n",
      "Epoch 507/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.2125 - val_loss: 35.4279\n",
      "Epoch 508/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.2204 - val_loss: 35.9586\n",
      "Epoch 509/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.2444 - val_loss: 35.8398\n",
      "Epoch 510/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.2108 - val_loss: 35.8739\n",
      "Epoch 511/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1804 - val_loss: 35.6816\n",
      "Epoch 512/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1493 - val_loss: 35.6275\n",
      "Epoch 513/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.1495 - val_loss: 35.6509\n",
      "Epoch 514/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1714 - val_loss: 35.5008\n",
      "Epoch 515/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1576 - val_loss: 35.5388\n",
      "Epoch 516/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1513 - val_loss: 36.0435\n",
      "Epoch 517/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.1755 - val_loss: 35.6955\n",
      "Epoch 518/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1863 - val_loss: 35.7496\n",
      "Epoch 519/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1987 - val_loss: 35.6906\n",
      "Epoch 520/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.1596 - val_loss: 35.5077\n",
      "Epoch 521/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.1534 - val_loss: 35.4162\n",
      "Epoch 522/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1304 - val_loss: 35.8394\n",
      "Epoch 523/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1451 - val_loss: 35.4179\n",
      "Epoch 524/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.1188 - val_loss: 35.5796\n",
      "Epoch 525/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1360 - val_loss: 35.7381\n",
      "Epoch 526/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.1075 - val_loss: 35.6653\n",
      "Epoch 527/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1194 - val_loss: 35.4905\n",
      "Epoch 528/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0911 - val_loss: 35.7620\n",
      "Epoch 529/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.1051 - val_loss: 35.7354\n",
      "Epoch 530/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.1122 - val_loss: 35.7895\n",
      "Epoch 531/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.1130 - val_loss: 35.5905\n",
      "Epoch 532/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.0975 - val_loss: 35.9504\n",
      "Epoch 533/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.1399 - val_loss: 35.7572\n",
      "Epoch 534/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1229 - val_loss: 35.5628\n",
      "Epoch 535/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0795 - val_loss: 35.6577\n",
      "Epoch 536/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1397 - val_loss: 35.7447\n",
      "Epoch 537/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.1146 - val_loss: 35.3869\n",
      "Epoch 538/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0931 - val_loss: 35.8093\n",
      "Epoch 539/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1000 - val_loss: 35.4277\n",
      "Epoch 540/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1259 - val_loss: 35.5832\n",
      "Epoch 541/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.0978 - val_loss: 35.5979\n",
      "Epoch 542/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0850 - val_loss: 35.6566\n",
      "Epoch 543/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.1282 - val_loss: 35.7502\n",
      "Epoch 544/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.1062 - val_loss: 35.4819\n",
      "Epoch 545/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0831 - val_loss: 35.4702\n",
      "Epoch 546/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.0615 - val_loss: 35.7878\n",
      "Epoch 547/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0794 - val_loss: 35.6461\n",
      "Epoch 548/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1301 - val_loss: 35.8175\n",
      "Epoch 549/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1249 - val_loss: 35.6963\n",
      "Epoch 550/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0745 - val_loss: 35.6509\n",
      "Epoch 551/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.0942 - val_loss: 35.4064\n",
      "Epoch 552/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.0610 - val_loss: 35.4449\n",
      "Epoch 553/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0583 - val_loss: 35.7439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.0661 - val_loss: 35.4708\n",
      "Epoch 555/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.0493 - val_loss: 35.4685\n",
      "Epoch 556/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0400 - val_loss: 35.4105\n",
      "Epoch 557/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.0592 - val_loss: 35.5007\n",
      "Epoch 558/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0692 - val_loss: 35.5467\n",
      "Epoch 559/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0440 - val_loss: 35.7638\n",
      "Epoch 560/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0532 - val_loss: 35.6007\n",
      "Epoch 561/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0827 - val_loss: 35.5594\n",
      "Epoch 562/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.0425 - val_loss: 35.3128\n",
      "Epoch 563/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0570 - val_loss: 35.6532\n",
      "Epoch 564/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0214 - val_loss: 35.7010\n",
      "Epoch 565/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0333 - val_loss: 35.4135\n",
      "Epoch 566/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0086 - val_loss: 35.4044\n",
      "Epoch 567/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0115 - val_loss: 35.6553\n",
      "Epoch 568/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9996 - val_loss: 35.6133\n",
      "Epoch 569/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.0307 - val_loss: 35.8014\n",
      "Epoch 570/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.0621 - val_loss: 35.0135\n",
      "Epoch 571/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0183 - val_loss: 35.9911\n",
      "Epoch 572/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.0239 - val_loss: 35.8084\n",
      "Epoch 573/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0229 - val_loss: 35.6306\n",
      "Epoch 574/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0114 - val_loss: 35.4198\n",
      "Epoch 575/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9999 - val_loss: 35.5406\n",
      "Epoch 576/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.9890 - val_loss: 35.6455\n",
      "Epoch 577/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9942 - val_loss: 35.6178\n",
      "Epoch 578/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0183 - val_loss: 35.5982\n",
      "Epoch 579/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0314 - val_loss: 35.7349\n",
      "Epoch 580/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9764 - val_loss: 35.4966\n",
      "Epoch 581/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9994 - val_loss: 35.3153\n",
      "Epoch 582/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0077 - val_loss: 35.7941\n",
      "Epoch 583/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.0143 - val_loss: 35.5457\n",
      "Epoch 584/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.0183 - val_loss: 35.5298\n",
      "Epoch 585/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0261 - val_loss: 35.5436\n",
      "Epoch 586/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9820 - val_loss: 35.5816\n",
      "Epoch 587/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.9992 - val_loss: 35.6039\n",
      "Epoch 588/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9825 - val_loss: 35.4023\n",
      "Epoch 589/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.9749 - val_loss: 35.4777\n",
      "Epoch 590/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9641 - val_loss: 35.2482\n",
      "Epoch 591/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9501 - val_loss: 35.2692\n",
      "Epoch 592/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9944 - val_loss: 35.4291\n",
      "Epoch 593/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9645 - val_loss: 35.4392\n",
      "Epoch 594/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9438 - val_loss: 35.5906\n",
      "Epoch 595/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.9617 - val_loss: 35.2758\n",
      "Epoch 596/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9776 - val_loss: 35.5475\n",
      "Epoch 597/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.9810 - val_loss: 35.5290\n",
      "Epoch 598/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9475 - val_loss: 35.4450\n",
      "Epoch 599/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.9375 - val_loss: 35.4348\n",
      "Epoch 600/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.9449 - val_loss: 35.6738\n",
      "Epoch 601/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.9627 - val_loss: 35.4671\n",
      "Epoch 602/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9325 - val_loss: 35.5232\n",
      "Epoch 603/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.9217 - val_loss: 35.6058\n",
      "Epoch 604/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.9436 - val_loss: 35.4889\n",
      "Epoch 605/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9263 - val_loss: 35.2871\n",
      "Epoch 606/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9246 - val_loss: 35.3780\n",
      "Epoch 607/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.9175 - val_loss: 35.6149\n",
      "Epoch 608/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9121 - val_loss: 35.5080\n",
      "Epoch 609/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.9305 - val_loss: 35.5428\n",
      "Epoch 610/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9417 - val_loss: 35.5623\n",
      "Epoch 611/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9279 - val_loss: 35.3382\n",
      "Epoch 612/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9550 - val_loss: 35.6604\n",
      "Epoch 613/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9344 - val_loss: 35.4192\n",
      "Epoch 614/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9388 - val_loss: 35.3877\n",
      "Epoch 615/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.9172 - val_loss: 35.4662\n",
      "Epoch 616/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.9317 - val_loss: 35.4647\n",
      "Epoch 617/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9186 - val_loss: 35.4489\n",
      "Epoch 618/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.9259 - val_loss: 35.5169\n",
      "Epoch 619/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9202 - val_loss: 35.4829\n",
      "Epoch 620/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.9494 - val_loss: 35.7268\n",
      "Epoch 621/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9554 - val_loss: 35.6337\n",
      "Epoch 622/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9465 - val_loss: 35.4693\n",
      "Epoch 623/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9153 - val_loss: 35.4365\n",
      "Epoch 624/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.9019 - val_loss: 35.5904\n",
      "Epoch 625/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.9199 - val_loss: 35.4670\n",
      "Epoch 626/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8945 - val_loss: 35.3982\n",
      "Epoch 627/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.8849 - val_loss: 35.5090\n",
      "Epoch 628/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8997 - val_loss: 35.6009\n",
      "Epoch 629/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9037 - val_loss: 35.6577\n",
      "Epoch 630/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8886 - val_loss: 35.2691\n",
      "Epoch 631/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8814 - val_loss: 35.1376\n",
      "Epoch 632/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.9127 - val_loss: 35.9031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 633/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.9024 - val_loss: 35.5781\n",
      "Epoch 634/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8836 - val_loss: 35.5090\n",
      "Epoch 635/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8727 - val_loss: 35.4894\n",
      "Epoch 636/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8873 - val_loss: 35.3963\n",
      "Epoch 637/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.9176 - val_loss: 35.6289\n",
      "Epoch 638/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.8897 - val_loss: 35.3715\n",
      "Epoch 639/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.8825 - val_loss: 35.6817\n",
      "Epoch 640/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8996 - val_loss: 35.4140\n",
      "Epoch 641/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8620 - val_loss: 35.4192\n",
      "Epoch 642/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.8683 - val_loss: 35.4322\n",
      "Epoch 643/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.8617 - val_loss: 35.5225\n",
      "Epoch 644/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8495 - val_loss: 35.3780\n",
      "Epoch 645/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8609 - val_loss: 35.4941\n",
      "Epoch 646/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8593 - val_loss: 35.4753\n",
      "Epoch 647/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8508 - val_loss: 35.4153\n",
      "Epoch 648/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8547 - val_loss: 35.5377\n",
      "Epoch 649/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8625 - val_loss: 35.5553\n",
      "Epoch 650/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8594 - val_loss: 35.4246\n",
      "Epoch 651/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8766 - val_loss: 35.4907\n",
      "Epoch 652/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8590 - val_loss: 35.5092\n",
      "Epoch 653/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8591 - val_loss: 35.3873\n",
      "Epoch 654/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.8477 - val_loss: 35.6471\n",
      "Epoch 655/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8461 - val_loss: 35.4725\n",
      "Epoch 656/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8552 - val_loss: 35.3094\n",
      "Epoch 657/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8451 - val_loss: 35.6508\n",
      "Epoch 658/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8499 - val_loss: 35.2900\n",
      "Epoch 659/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.8328 - val_loss: 35.4642\n",
      "Epoch 660/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.8284 - val_loss: 35.5612\n",
      "Epoch 661/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.8409 - val_loss: 35.4399\n",
      "Epoch 662/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8393 - val_loss: 35.5014\n",
      "Epoch 663/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 2.8503 - val_loss: 35.7424\n",
      "Epoch 664/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8399 - val_loss: 35.2410\n",
      "Epoch 665/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8518 - val_loss: 35.6091\n",
      "Epoch 666/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8278 - val_loss: 35.6244\n",
      "Epoch 667/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8207 - val_loss: 35.5169\n",
      "Epoch 668/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8180 - val_loss: 35.4687\n",
      "Epoch 669/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8260 - val_loss: 35.5458\n",
      "Epoch 670/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8383 - val_loss: 35.3598\n",
      "Epoch 671/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8451 - val_loss: 35.5575\n",
      "Epoch 672/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8186 - val_loss: 35.4409\n",
      "Epoch 673/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8162 - val_loss: 35.4454\n",
      "Epoch 674/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8141 - val_loss: 35.4171\n",
      "Epoch 675/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8159 - val_loss: 35.5694\n",
      "Epoch 676/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.8134 - val_loss: 35.4364\n",
      "Epoch 677/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8066 - val_loss: 35.4289\n",
      "Epoch 678/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8079 - val_loss: 35.5735\n",
      "Epoch 679/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.8191 - val_loss: 35.5318\n",
      "Epoch 680/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8130 - val_loss: 35.3757\n",
      "Epoch 681/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8191 - val_loss: 35.4723\n",
      "Epoch 682/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8096 - val_loss: 35.3981\n",
      "Epoch 683/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8089 - val_loss: 35.4180\n",
      "Epoch 684/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8079 - val_loss: 35.4078\n",
      "Epoch 685/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8021 - val_loss: 35.4595\n",
      "Epoch 686/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8070 - val_loss: 35.4407\n",
      "Epoch 687/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.7967 - val_loss: 35.6429\n",
      "Epoch 688/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.7967 - val_loss: 35.2906\n",
      "Epoch 689/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.8065 - val_loss: 35.6584\n",
      "Epoch 690/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8109 - val_loss: 35.5144\n",
      "Epoch 691/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8038 - val_loss: 35.5641\n",
      "Epoch 692/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7973 - val_loss: 35.5118\n",
      "Epoch 693/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7939 - val_loss: 35.5505\n",
      "Epoch 694/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8067 - val_loss: 35.3311\n",
      "Epoch 695/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7973 - val_loss: 35.5425\n",
      "Epoch 696/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 2.7821 - val_loss: 35.4535\n",
      "Epoch 697/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7854 - val_loss: 35.4163\n",
      "Epoch 698/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.7868 - val_loss: 35.3784\n",
      "Epoch 699/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7827 - val_loss: 35.4925\n",
      "Epoch 700/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7847 - val_loss: 35.5606\n",
      "Epoch 701/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8012 - val_loss: 35.5452\n",
      "Epoch 702/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7905 - val_loss: 35.6616\n",
      "Epoch 703/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7848 - val_loss: 35.5029\n",
      "Epoch 704/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7872 - val_loss: 35.5203\n",
      "Epoch 705/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7792 - val_loss: 35.4987\n",
      "Epoch 706/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7794 - val_loss: 35.4467\n",
      "Epoch 707/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7832 - val_loss: 35.5594\n",
      "Epoch 708/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.7757 - val_loss: 35.4704\n",
      "Epoch 709/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7974 - val_loss: 35.5092\n",
      "Epoch 710/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7778 - val_loss: 35.5126\n",
      "Epoch 711/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7798 - val_loss: 35.5179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 712/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7802 - val_loss: 35.5060\n",
      "Epoch 713/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7701 - val_loss: 35.4261\n",
      "Epoch 714/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7799 - val_loss: 35.4259\n",
      "Epoch 715/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7702 - val_loss: 35.6258\n",
      "Epoch 716/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7728 - val_loss: 35.5528\n",
      "Epoch 717/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7697 - val_loss: 35.4993\n",
      "Epoch 718/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7779 - val_loss: 35.3887\n",
      "Epoch 719/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7856 - val_loss: 35.4267\n",
      "Epoch 720/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7623 - val_loss: 35.6412\n",
      "Epoch 721/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7715 - val_loss: 35.4250\n",
      "Epoch 722/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.7644 - val_loss: 35.4343\n",
      "Epoch 723/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7778 - val_loss: 35.5673\n",
      "Epoch 724/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7798 - val_loss: 35.4014\n",
      "Epoch 725/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7643 - val_loss: 35.5132\n",
      "Epoch 726/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7604 - val_loss: 35.4998\n",
      "Epoch 727/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7616 - val_loss: 35.4213\n",
      "Epoch 728/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7686 - val_loss: 35.5246\n",
      "Epoch 729/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7571 - val_loss: 35.5821\n",
      "Epoch 730/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7595 - val_loss: 35.4187\n",
      "Epoch 731/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7510 - val_loss: 35.4248\n",
      "Epoch 732/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7695 - val_loss: 35.5114\n",
      "Epoch 733/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7660 - val_loss: 35.4292\n",
      "Epoch 734/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7513 - val_loss: 35.4810\n",
      "Epoch 735/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7569 - val_loss: 35.4904\n",
      "Epoch 736/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7521 - val_loss: 35.5012\n",
      "Epoch 737/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7521 - val_loss: 35.4526\n",
      "Epoch 738/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7513 - val_loss: 35.3859\n",
      "Epoch 739/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7487 - val_loss: 35.4536\n",
      "Epoch 740/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7514 - val_loss: 35.5159\n",
      "Epoch 741/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7486 - val_loss: 35.4452\n",
      "Epoch 742/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.7568 - val_loss: 35.4587\n",
      "Epoch 743/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7498 - val_loss: 35.4863\n",
      "Epoch 744/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7543 - val_loss: 35.4392\n",
      "Epoch 745/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7499 - val_loss: 35.4066\n",
      "Epoch 746/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7476 - val_loss: 35.4838\n",
      "Epoch 747/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7473 - val_loss: 35.4555\n",
      "Epoch 748/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7448 - val_loss: 35.4125\n",
      "Epoch 749/2000\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 2.7451 - val_loss: 35.4801\n",
      "Epoch 750/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.7432 - val_loss: 35.5519\n",
      "Epoch 751/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7376 - val_loss: 35.4457\n",
      "Epoch 752/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7376 - val_loss: 35.4361\n",
      "Epoch 753/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.7489 - val_loss: 35.3748\n",
      "Epoch 754/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7411 - val_loss: 35.4893\n",
      "Epoch 755/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7416 - val_loss: 35.4824\n",
      "Epoch 756/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7419 - val_loss: 35.3945\n",
      "Epoch 757/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7415 - val_loss: 35.4384\n",
      "Epoch 758/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7380 - val_loss: 35.4168\n",
      "Epoch 759/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7387 - val_loss: 35.4785\n",
      "Epoch 760/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7394 - val_loss: 35.4933\n",
      "Epoch 761/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7374 - val_loss: 35.4956\n",
      "Epoch 762/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7371 - val_loss: 35.4607\n",
      "Epoch 763/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7363 - val_loss: 35.4064\n",
      "Epoch 764/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7336 - val_loss: 35.4504\n",
      "Epoch 765/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7373 - val_loss: 35.4255\n",
      "Epoch 766/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7363 - val_loss: 35.4411\n",
      "Epoch 767/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7325 - val_loss: 35.4687\n",
      "Epoch 768/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7342 - val_loss: 35.4406\n",
      "Epoch 769/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7314 - val_loss: 35.4659\n",
      "Epoch 770/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7342 - val_loss: 35.4754\n",
      "Epoch 771/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7326 - val_loss: 35.4227\n",
      "Epoch 772/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7413 - val_loss: 35.4002\n",
      "Epoch 773/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7312 - val_loss: 35.4757\n",
      "Epoch 774/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7301 - val_loss: 35.4312\n",
      "Epoch 775/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7286 - val_loss: 35.4575\n",
      "Epoch 776/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7305 - val_loss: 35.4464\n",
      "Epoch 777/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7308 - val_loss: 35.4434\n",
      "Epoch 778/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7311 - val_loss: 35.4769\n",
      "Epoch 779/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7292 - val_loss: 35.4879\n",
      "Epoch 780/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7277 - val_loss: 35.5169\n",
      "Epoch 781/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7290 - val_loss: 35.4745\n",
      "Epoch 782/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7276 - val_loss: 35.4729\n",
      "Epoch 783/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7274 - val_loss: 35.4646\n",
      "Epoch 784/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7295 - val_loss: 35.4836\n",
      "Epoch 785/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7272 - val_loss: 35.4681\n",
      "Epoch 786/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7263 - val_loss: 35.5042\n",
      "Epoch 787/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7271 - val_loss: 35.4537\n",
      "Epoch 788/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7259 - val_loss: 35.4690\n",
      "Epoch 789/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7265 - val_loss: 35.4805\n",
      "Epoch 790/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7248 - val_loss: 35.4765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 791/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7256 - val_loss: 35.4853\n",
      "Epoch 792/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7266 - val_loss: 35.4900\n",
      "Epoch 793/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7249 - val_loss: 35.4647\n",
      "Epoch 794/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7251 - val_loss: 35.4682\n",
      "Epoch 795/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7228 - val_loss: 35.4817\n",
      "Epoch 796/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7230 - val_loss: 35.4572\n",
      "Epoch 797/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7229 - val_loss: 35.4652\n",
      "Epoch 798/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7221 - val_loss: 35.4596\n",
      "Epoch 799/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7234 - val_loss: 35.4564\n",
      "Epoch 800/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7225 - val_loss: 35.4749\n",
      "Epoch 801/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7214 - val_loss: 35.4577\n",
      "Epoch 802/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7212 - val_loss: 35.4652\n",
      "Epoch 803/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7210 - val_loss: 35.4556\n",
      "Epoch 804/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7209 - val_loss: 35.4723\n",
      "Epoch 805/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7237 - val_loss: 35.4660\n",
      "Epoch 806/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7209 - val_loss: 35.4706\n",
      "Epoch 807/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7214 - val_loss: 35.4616\n",
      "Epoch 808/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7209 - val_loss: 35.4581\n",
      "Epoch 809/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7199 - val_loss: 35.4665\n",
      "Epoch 810/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7214 - val_loss: 35.4736\n",
      "Epoch 811/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7202 - val_loss: 35.4614\n",
      "Epoch 812/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7194 - val_loss: 35.4612\n",
      "Epoch 813/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7196 - val_loss: 35.4577\n",
      "Epoch 814/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7194 - val_loss: 35.4627\n",
      "Epoch 815/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7201 - val_loss: 35.4587\n",
      "Epoch 816/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7192 - val_loss: 35.4587\n",
      "Epoch 817/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7188 - val_loss: 35.4666\n",
      "Epoch 818/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7191 - val_loss: 35.4692\n",
      "Epoch 819/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7188 - val_loss: 35.4691\n",
      "Epoch 820/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7191 - val_loss: 35.4693\n",
      "Epoch 821/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7191 - val_loss: 35.4703\n",
      "Epoch 822/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7186 - val_loss: 35.4693\n",
      "Epoch 823/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7186 - val_loss: 35.4631\n",
      "Epoch 824/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7185 - val_loss: 35.4658\n",
      "Epoch 825/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7184 - val_loss: 35.4686\n",
      "Epoch 826/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.7180 - val_loss: 35.4672\n",
      "Epoch 827/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7179 - val_loss: 35.4639\n",
      "Epoch 828/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7182 - val_loss: 35.4603\n",
      "Epoch 829/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.7180 - val_loss: 35.4652\n",
      "Epoch 830/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 2.7180 - val_loss: 35.4692\n",
      "Epoch 831/2000\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.7177 - val_loss: 35.4678\n",
      "Epoch 832/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7178 - val_loss: 35.4671\n",
      "Epoch 833/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7176 - val_loss: 35.4641\n",
      "Epoch 834/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7176 - val_loss: 35.4652\n",
      "Epoch 835/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7176 - val_loss: 35.4643\n",
      "Epoch 836/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7173 - val_loss: 35.4647\n",
      "Epoch 837/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7174 - val_loss: 35.4654\n",
      "Epoch 838/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7174 - val_loss: 35.4666\n",
      "Epoch 839/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7174 - val_loss: 35.4649\n",
      "Epoch 840/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7173 - val_loss: 35.4654\n",
      "Epoch 841/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7173 - val_loss: 35.4662\n",
      "Epoch 842/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7173 - val_loss: 35.4657\n",
      "Epoch 843/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7172 - val_loss: 35.4653\n",
      "Epoch 844/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7172 - val_loss: 35.4656\n",
      "Epoch 845/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7172 - val_loss: 35.4656\n",
      "Epoch 846/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7172 - val_loss: 35.4652\n",
      "Epoch 847/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7171 - val_loss: 35.4654\n",
      "Epoch 848/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7171 - val_loss: 35.4652\n",
      "Epoch 849/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7171 - val_loss: 35.4653\n",
      "Epoch 850/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7171 - val_loss: 35.4653\n",
      "Epoch 851/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7171 - val_loss: 35.4653\n",
      "Epoch 852/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7340 - val_loss: 35.5212\n",
      "Epoch 853/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.8091 - val_loss: 35.5684\n",
      "Epoch 854/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9204 - val_loss: 35.6338\n",
      "Epoch 855/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9826 - val_loss: 35.6674\n",
      "Epoch 856/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.1542 - val_loss: 35.0261\n",
      "Epoch 857/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.0125 - val_loss: 35.2929\n",
      "Epoch 858/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.1070 - val_loss: 35.4076\n",
      "Epoch 859/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.2200 - val_loss: 36.5501\n",
      "Epoch 860/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 3.7717 - val_loss: 36.2204\n",
      "Epoch 861/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 3.3131 - val_loss: 35.6582\n",
      "Epoch 862/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 3.0801 - val_loss: 35.5422\n",
      "Epoch 863/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 3.1322 - val_loss: 35.9048\n",
      "Epoch 864/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1127 - val_loss: 35.4766\n",
      "Epoch 865/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.1537 - val_loss: 36.1498\n",
      "Epoch 866/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 3.0469 - val_loss: 35.3329\n",
      "Epoch 867/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.9347 - val_loss: 35.1684\n",
      "Epoch 868/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8730 - val_loss: 35.5506\n",
      "Epoch 869/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8523 - val_loss: 35.4749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 870/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8221 - val_loss: 35.6634\n",
      "Epoch 871/2000\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.8231 - val_loss: 34.8195\n",
      "Epoch 872/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8475 - val_loss: 35.3576\n",
      "Epoch 873/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.9103 - val_loss: 35.1885\n",
      "Epoch 874/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8657 - val_loss: 35.4350\n",
      "Epoch 875/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8541 - val_loss: 35.0214\n",
      "Epoch 876/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8158 - val_loss: 35.3224\n",
      "Epoch 877/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8170 - val_loss: 35.6394\n",
      "Epoch 878/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8234 - val_loss: 35.2423\n",
      "Epoch 879/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8845 - val_loss: 35.5144\n",
      "Epoch 880/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.9103 - val_loss: 35.7176\n",
      "Epoch 881/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8440 - val_loss: 35.6195\n",
      "Epoch 882/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7895 - val_loss: 35.3859\n",
      "Epoch 883/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7874 - val_loss: 35.4933\n",
      "Epoch 884/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7900 - val_loss: 35.3255\n",
      "Epoch 885/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7812 - val_loss: 35.7086\n",
      "Epoch 886/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8117 - val_loss: 35.4303\n",
      "Epoch 887/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8221 - val_loss: 35.3485\n",
      "Epoch 888/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8205 - val_loss: 35.4835\n",
      "Epoch 889/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.8531 - val_loss: 35.2618\n",
      "Epoch 890/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7426 - val_loss: 35.7374\n",
      "Epoch 891/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7521 - val_loss: 35.4999\n",
      "Epoch 892/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7725 - val_loss: 35.6540\n",
      "Epoch 893/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7738 - val_loss: 35.6145\n",
      "Epoch 894/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7757 - val_loss: 35.5946\n",
      "Epoch 895/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.7358 - val_loss: 35.1998\n",
      "Epoch 896/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7663 - val_loss: 35.8276\n",
      "Epoch 897/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7604 - val_loss: 35.3720\n",
      "Epoch 898/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7544 - val_loss: 35.1057\n",
      "Epoch 899/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7558 - val_loss: 35.6206\n",
      "Epoch 900/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7484 - val_loss: 35.6811\n",
      "Epoch 901/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7494 - val_loss: 35.7583\n",
      "Epoch 902/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7277 - val_loss: 35.4423\n",
      "Epoch 903/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7223 - val_loss: 35.6810\n",
      "Epoch 904/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6965 - val_loss: 35.4385\n",
      "Epoch 905/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.6865 - val_loss: 35.3676\n",
      "Epoch 906/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7181 - val_loss: 35.4789\n",
      "Epoch 907/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7769 - val_loss: 35.6711\n",
      "Epoch 908/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8019 - val_loss: 35.6537\n",
      "Epoch 909/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7756 - val_loss: 35.5044\n",
      "Epoch 910/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7236 - val_loss: 35.6223\n",
      "Epoch 911/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7279 - val_loss: 35.5451\n",
      "Epoch 912/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7399 - val_loss: 35.7604\n",
      "Epoch 913/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7363 - val_loss: 35.4809\n",
      "Epoch 914/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7087 - val_loss: 35.7846\n",
      "Epoch 915/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.6902 - val_loss: 35.7676\n",
      "Epoch 916/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.6951 - val_loss: 35.6629\n",
      "Epoch 917/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.6993 - val_loss: 35.8742\n",
      "Epoch 918/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7135 - val_loss: 35.1976\n",
      "Epoch 919/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6780 - val_loss: 35.9256\n",
      "Epoch 920/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7000 - val_loss: 35.6598\n",
      "Epoch 921/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.6797 - val_loss: 35.8236\n",
      "Epoch 922/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.7206 - val_loss: 35.4988\n",
      "Epoch 923/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6703 - val_loss: 35.7082\n",
      "Epoch 924/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7611 - val_loss: 35.3160\n",
      "Epoch 925/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.8073 - val_loss: 35.6402\n",
      "Epoch 926/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7815 - val_loss: 35.6947\n",
      "Epoch 927/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7804 - val_loss: 35.9511\n",
      "Epoch 928/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7197 - val_loss: 35.3309\n",
      "Epoch 929/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.6961 - val_loss: 35.5713\n",
      "Epoch 930/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6565 - val_loss: 35.6740\n",
      "Epoch 931/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.6961 - val_loss: 35.2038\n",
      "Epoch 932/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7328 - val_loss: 35.6745\n",
      "Epoch 933/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.6965 - val_loss: 35.6984\n",
      "Epoch 934/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.6803 - val_loss: 35.2571\n",
      "Epoch 935/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.6599 - val_loss: 35.5878\n",
      "Epoch 936/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6582 - val_loss: 35.6802\n",
      "Epoch 937/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6685 - val_loss: 35.3275\n",
      "Epoch 938/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.6485 - val_loss: 35.4998\n",
      "Epoch 939/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.6773 - val_loss: 35.8042\n",
      "Epoch 940/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7141 - val_loss: 35.3653\n",
      "Epoch 941/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6907 - val_loss: 35.6609\n",
      "Epoch 942/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6649 - val_loss: 35.4787\n",
      "Epoch 943/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.6494 - val_loss: 35.9390\n",
      "Epoch 944/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.6957 - val_loss: 35.6492\n",
      "Epoch 945/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.6831 - val_loss: 35.5316\n",
      "Epoch 946/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6746 - val_loss: 35.4595\n",
      "Epoch 947/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.6937 - val_loss: 35.3747\n",
      "Epoch 948/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6970 - val_loss: 35.6732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 949/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.7500 - val_loss: 35.8202\n",
      "Epoch 950/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.6678 - val_loss: 35.6690\n",
      "Epoch 951/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6613 - val_loss: 35.1851\n",
      "Epoch 952/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.6346 - val_loss: 35.4847\n",
      "Epoch 953/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.6483 - val_loss: 35.6774\n",
      "Epoch 954/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6025 - val_loss: 35.6618\n",
      "Epoch 955/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.6078 - val_loss: 35.3326\n",
      "Epoch 956/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6276 - val_loss: 35.5745\n",
      "Epoch 957/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6094 - val_loss: 35.4450\n",
      "Epoch 958/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6113 - val_loss: 35.5229\n",
      "Epoch 959/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.6773 - val_loss: 35.6039\n",
      "Epoch 960/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6262 - val_loss: 35.6828\n",
      "Epoch 961/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6214 - val_loss: 35.7127\n",
      "Epoch 962/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.5922 - val_loss: 35.4303\n",
      "Epoch 963/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.5807 - val_loss: 35.6687\n",
      "Epoch 964/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.6158 - val_loss: 35.3132\n",
      "Epoch 965/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.6032 - val_loss: 35.5610\n",
      "Epoch 966/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.6207 - val_loss: 35.7220\n",
      "Epoch 967/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6186 - val_loss: 35.1334\n",
      "Epoch 968/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6074 - val_loss: 35.3309\n",
      "Epoch 969/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.6256 - val_loss: 35.5945\n",
      "Epoch 970/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6711 - val_loss: 35.7155\n",
      "Epoch 971/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.7178 - val_loss: 35.6637\n",
      "Epoch 972/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.6441 - val_loss: 35.9310\n",
      "Epoch 973/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.6458 - val_loss: 35.5203\n",
      "Epoch 974/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6180 - val_loss: 35.5332\n",
      "Epoch 975/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.5691 - val_loss: 35.6228\n",
      "Epoch 976/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.6487 - val_loss: 35.7439\n",
      "Epoch 977/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.6014 - val_loss: 35.4566\n",
      "Epoch 978/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.5839 - val_loss: 35.7871\n",
      "Epoch 979/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6238 - val_loss: 35.4985\n",
      "Epoch 980/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6674 - val_loss: 35.8406\n",
      "Epoch 981/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.6269 - val_loss: 35.7133\n",
      "Epoch 982/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6186 - val_loss: 35.4694\n",
      "Epoch 983/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6325 - val_loss: 35.6539\n",
      "Epoch 984/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6847 - val_loss: 35.5749\n",
      "Epoch 985/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.6145 - val_loss: 35.3751\n",
      "Epoch 986/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.5557 - val_loss: 35.6181\n",
      "Epoch 987/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.5428 - val_loss: 35.5021\n",
      "Epoch 988/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.6620 - val_loss: 35.4301\n",
      "Epoch 989/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.5945 - val_loss: 35.8684\n",
      "Epoch 990/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.5532 - val_loss: 35.2708\n",
      "Epoch 991/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.5512 - val_loss: 35.7876\n",
      "Epoch 992/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.5924 - val_loss: 35.7599\n",
      "Epoch 993/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.5691 - val_loss: 35.6111\n",
      "Epoch 994/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.5677 - val_loss: 35.9117\n",
      "Epoch 995/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.5427 - val_loss: 35.6840\n",
      "Epoch 996/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.5446 - val_loss: 35.4098\n",
      "Epoch 997/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.5563 - val_loss: 35.7523\n",
      "Epoch 998/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.5468 - val_loss: 35.6970\n",
      "Epoch 999/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.5492 - val_loss: 35.6439\n",
      "Epoch 1000/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.5678 - val_loss: 35.4965\n",
      "Epoch 1001/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.5925 - val_loss: 35.5021\n",
      "Epoch 1002/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.5725 - val_loss: 35.3970\n",
      "Epoch 1003/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.5961 - val_loss: 35.4900\n",
      "Epoch 1004/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.5650 - val_loss: 35.3866\n",
      "Epoch 1005/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.5314 - val_loss: 35.4745\n",
      "Epoch 1006/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.5025 - val_loss: 35.4629\n",
      "Epoch 1007/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.5172 - val_loss: 35.5489\n",
      "Epoch 1008/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.5429 - val_loss: 35.5750\n",
      "Epoch 1009/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.5603 - val_loss: 35.4162\n",
      "Epoch 1010/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.5654 - val_loss: 35.7196\n",
      "Epoch 1011/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.5029 - val_loss: 35.7571\n",
      "Epoch 1012/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.5344 - val_loss: 35.6483\n",
      "Epoch 1013/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.5053 - val_loss: 35.6665\n",
      "Epoch 1014/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.5083 - val_loss: 35.5573\n",
      "Epoch 1015/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.5097 - val_loss: 35.6108\n",
      "Epoch 1016/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.5337 - val_loss: 35.5033\n",
      "Epoch 1017/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.5664 - val_loss: 35.5582\n",
      "Epoch 1018/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.5744 - val_loss: 34.9724\n",
      "Epoch 1019/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.5416 - val_loss: 35.4520\n",
      "Epoch 1020/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.4916 - val_loss: 35.3448\n",
      "Epoch 1021/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.5473 - val_loss: 35.4996\n",
      "Epoch 1022/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4754 - val_loss: 35.5218\n",
      "Epoch 1023/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.5173 - val_loss: 35.6865\n",
      "Epoch 1024/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.5239 - val_loss: 35.7521\n",
      "Epoch 1025/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.4842 - val_loss: 35.5366\n",
      "Epoch 1026/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.5362 - val_loss: 35.8086\n",
      "Epoch 1027/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 29ms/step - loss: 2.5822 - val_loss: 35.6010\n",
      "Epoch 1028/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.5558 - val_loss: 35.3476\n",
      "Epoch 1029/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4727 - val_loss: 35.6954\n",
      "Epoch 1030/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4743 - val_loss: 35.5920\n",
      "Epoch 1031/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.5070 - val_loss: 35.5086\n",
      "Epoch 1032/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.4605 - val_loss: 35.4623\n",
      "Epoch 1033/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4875 - val_loss: 35.5251\n",
      "Epoch 1034/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.5064 - val_loss: 35.4424\n",
      "Epoch 1035/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.4829 - val_loss: 35.1898\n",
      "Epoch 1036/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.4894 - val_loss: 35.4811\n",
      "Epoch 1037/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4477 - val_loss: 35.5819\n",
      "Epoch 1038/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.4748 - val_loss: 35.4121\n",
      "Epoch 1039/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4740 - val_loss: 35.6116\n",
      "Epoch 1040/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.4350 - val_loss: 35.2861\n",
      "Epoch 1041/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.4474 - val_loss: 35.5486\n",
      "Epoch 1042/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.4392 - val_loss: 35.3525\n",
      "Epoch 1043/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.4393 - val_loss: 35.6814\n",
      "Epoch 1044/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4963 - val_loss: 35.1109\n",
      "Epoch 1045/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.4578 - val_loss: 35.3343\n",
      "Epoch 1046/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4485 - val_loss: 35.4847\n",
      "Epoch 1047/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4462 - val_loss: 35.5608\n",
      "Epoch 1048/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.4721 - val_loss: 35.3875\n",
      "Epoch 1049/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.4382 - val_loss: 35.2396\n",
      "Epoch 1050/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4403 - val_loss: 35.4529\n",
      "Epoch 1051/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.4410 - val_loss: 35.7192\n",
      "Epoch 1052/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4211 - val_loss: 35.3704\n",
      "Epoch 1053/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4198 - val_loss: 35.4693\n",
      "Epoch 1054/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4238 - val_loss: 35.3079\n",
      "Epoch 1055/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.4446 - val_loss: 35.7027\n",
      "Epoch 1056/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.4499 - val_loss: 35.4750\n",
      "Epoch 1057/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.4412 - val_loss: 35.2716\n",
      "Epoch 1058/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4507 - val_loss: 35.6528\n",
      "Epoch 1059/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4656 - val_loss: 35.1186\n",
      "Epoch 1060/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.4686 - val_loss: 35.2523\n",
      "Epoch 1061/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4638 - val_loss: 35.5351\n",
      "Epoch 1062/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.4518 - val_loss: 35.5878\n",
      "Epoch 1063/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3959 - val_loss: 35.3036\n",
      "Epoch 1064/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3974 - val_loss: 35.3828\n",
      "Epoch 1065/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.4404 - val_loss: 35.5357\n",
      "Epoch 1066/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.4568 - val_loss: 35.3248\n",
      "Epoch 1067/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4318 - val_loss: 35.6848\n",
      "Epoch 1068/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.4296 - val_loss: 35.5175\n",
      "Epoch 1069/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.4678 - val_loss: 35.5913\n",
      "Epoch 1070/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.5651 - val_loss: 35.4257\n",
      "Epoch 1071/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.5539 - val_loss: 35.7445\n",
      "Epoch 1072/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.5095 - val_loss: 35.2457\n",
      "Epoch 1073/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.4393 - val_loss: 35.3906\n",
      "Epoch 1074/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.4568 - val_loss: 34.9968\n",
      "Epoch 1075/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.4621 - val_loss: 35.6353\n",
      "Epoch 1076/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.4542 - val_loss: 35.2697\n",
      "Epoch 1077/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.4983 - val_loss: 35.0285\n",
      "Epoch 1078/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.5159 - val_loss: 35.3401\n",
      "Epoch 1079/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.4650 - val_loss: 35.5527\n",
      "Epoch 1080/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3769 - val_loss: 35.1572\n",
      "Epoch 1081/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4747 - val_loss: 35.2235\n",
      "Epoch 1082/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.4492 - val_loss: 35.4674\n",
      "Epoch 1083/2000\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.4304 - val_loss: 35.6000\n",
      "Epoch 1084/2000\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.3645 - val_loss: 34.8858\n",
      "Epoch 1085/2000\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 2.3942 - val_loss: 34.7160\n",
      "Epoch 1086/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4352 - val_loss: 35.3560\n",
      "Epoch 1087/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.4061 - val_loss: 35.1161\n",
      "Epoch 1088/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3977 - val_loss: 35.0955\n",
      "Epoch 1089/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3731 - val_loss: 35.4081\n",
      "Epoch 1090/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3663 - val_loss: 35.3077\n",
      "Epoch 1091/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3894 - val_loss: 35.4833\n",
      "Epoch 1092/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3449 - val_loss: 35.4145\n",
      "Epoch 1093/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3626 - val_loss: 35.3550\n",
      "Epoch 1094/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3625 - val_loss: 35.4574\n",
      "Epoch 1095/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3449 - val_loss: 35.3665\n",
      "Epoch 1096/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3388 - val_loss: 35.2343\n",
      "Epoch 1097/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3971 - val_loss: 35.4629\n",
      "Epoch 1098/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3849 - val_loss: 35.4948\n",
      "Epoch 1099/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3527 - val_loss: 35.3934\n",
      "Epoch 1100/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.3633 - val_loss: 35.3708\n",
      "Epoch 1101/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.3837 - val_loss: 35.4809\n",
      "Epoch 1102/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 2.3925 - val_loss: 35.3369\n",
      "Epoch 1103/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.3591 - val_loss: 35.3579\n",
      "Epoch 1104/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3512 - val_loss: 35.2722\n",
      "Epoch 1105/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4088 - val_loss: 35.4974\n",
      "Epoch 1106/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.3536 - val_loss: 35.3561\n",
      "Epoch 1107/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.3622 - val_loss: 35.3934\n",
      "Epoch 1108/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.3128 - val_loss: 35.4059\n",
      "Epoch 1109/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3453 - val_loss: 35.1489\n",
      "Epoch 1110/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3435 - val_loss: 35.1492\n",
      "Epoch 1111/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3254 - val_loss: 35.3924\n",
      "Epoch 1112/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.3295 - val_loss: 35.1832\n",
      "Epoch 1113/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.3769 - val_loss: 35.4310\n",
      "Epoch 1114/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3749 - val_loss: 35.3687\n",
      "Epoch 1115/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3319 - val_loss: 35.5499\n",
      "Epoch 1116/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.3289 - val_loss: 35.4454\n",
      "Epoch 1117/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.3101 - val_loss: 35.2998\n",
      "Epoch 1118/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.3010 - val_loss: 35.3010\n",
      "Epoch 1119/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3136 - val_loss: 35.5890\n",
      "Epoch 1120/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3512 - val_loss: 35.2566\n",
      "Epoch 1121/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.3405 - val_loss: 35.3940\n",
      "Epoch 1122/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3166 - val_loss: 35.3569\n",
      "Epoch 1123/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3188 - val_loss: 35.2292\n",
      "Epoch 1124/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.3682 - val_loss: 35.2216\n",
      "Epoch 1125/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.3715 - val_loss: 35.4678\n",
      "Epoch 1126/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3342 - val_loss: 35.1125\n",
      "Epoch 1127/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3734 - val_loss: 35.3543\n",
      "Epoch 1128/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.2991 - val_loss: 35.1088\n",
      "Epoch 1129/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.3205 - val_loss: 35.3840\n",
      "Epoch 1130/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3223 - val_loss: 35.4710\n",
      "Epoch 1131/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.3541 - val_loss: 35.4219\n",
      "Epoch 1132/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.3316 - val_loss: 35.3455\n",
      "Epoch 1133/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.2999 - val_loss: 35.2315\n",
      "Epoch 1134/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3515 - val_loss: 35.2016\n",
      "Epoch 1135/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3145 - val_loss: 35.1898\n",
      "Epoch 1136/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2987 - val_loss: 35.0870\n",
      "Epoch 1137/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2864 - val_loss: 35.3955\n",
      "Epoch 1138/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2806 - val_loss: 35.2548\n",
      "Epoch 1139/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2776 - val_loss: 35.3890\n",
      "Epoch 1140/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3176 - val_loss: 35.5550\n",
      "Epoch 1141/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.2773 - val_loss: 35.3027\n",
      "Epoch 1142/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2748 - val_loss: 35.2958\n",
      "Epoch 1143/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2575 - val_loss: 35.3279\n",
      "Epoch 1144/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2589 - val_loss: 35.2179\n",
      "Epoch 1145/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.2668 - val_loss: 35.3871\n",
      "Epoch 1146/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.3081 - val_loss: 35.3470\n",
      "Epoch 1147/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3283 - val_loss: 35.3937\n",
      "Epoch 1148/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3199 - val_loss: 35.2387\n",
      "Epoch 1149/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3063 - val_loss: 35.1202\n",
      "Epoch 1150/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3183 - val_loss: 35.0445\n",
      "Epoch 1151/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2714 - val_loss: 35.0229\n",
      "Epoch 1152/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.2574 - val_loss: 35.1982\n",
      "Epoch 1153/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.2639 - val_loss: 35.3593\n",
      "Epoch 1154/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2448 - val_loss: 35.2497\n",
      "Epoch 1155/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.2636 - val_loss: 35.2246\n",
      "Epoch 1156/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2433 - val_loss: 35.1529\n",
      "Epoch 1157/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3143 - val_loss: 35.0618\n",
      "Epoch 1158/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3261 - val_loss: 35.2653\n",
      "Epoch 1159/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3266 - val_loss: 35.3240\n",
      "Epoch 1160/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3145 - val_loss: 35.6913\n",
      "Epoch 1161/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2502 - val_loss: 35.3896\n",
      "Epoch 1162/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2809 - val_loss: 35.1118\n",
      "Epoch 1163/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2494 - val_loss: 35.3013\n",
      "Epoch 1164/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2660 - val_loss: 35.3085\n",
      "Epoch 1165/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.2783 - val_loss: 35.5177\n",
      "Epoch 1166/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.2509 - val_loss: 35.1967\n",
      "Epoch 1167/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.2690 - val_loss: 35.3610\n",
      "Epoch 1168/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2651 - val_loss: 35.3781\n",
      "Epoch 1169/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2461 - val_loss: 35.3925\n",
      "Epoch 1170/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.3267 - val_loss: 35.3103\n",
      "Epoch 1171/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.2253 - val_loss: 35.2402\n",
      "Epoch 1172/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2468 - val_loss: 35.1302\n",
      "Epoch 1173/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.2703 - val_loss: 35.0983\n",
      "Epoch 1174/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.2750 - val_loss: 34.9625\n",
      "Epoch 1175/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2321 - val_loss: 35.2379\n",
      "Epoch 1176/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3096 - val_loss: 34.9974\n",
      "Epoch 1177/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3157 - val_loss: 35.5144\n",
      "Epoch 1178/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3535 - val_loss: 35.3231\n",
      "Epoch 1179/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.2631 - val_loss: 35.0618\n",
      "Epoch 1180/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2399 - val_loss: 35.1218\n",
      "Epoch 1181/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.2418 - val_loss: 35.1337\n",
      "Epoch 1182/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2392 - val_loss: 35.2957\n",
      "Epoch 1183/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2813 - val_loss: 34.9838\n",
      "Epoch 1184/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.3189 - val_loss: 35.1325\n",
      "Epoch 1185/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2916 - val_loss: 35.3068\n",
      "Epoch 1186/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2736 - val_loss: 35.3273\n",
      "Epoch 1187/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2450 - val_loss: 35.2387\n",
      "Epoch 1188/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2800 - val_loss: 35.3587\n",
      "Epoch 1189/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.2353 - val_loss: 35.2331\n",
      "Epoch 1190/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2382 - val_loss: 35.1628\n",
      "Epoch 1191/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.2048 - val_loss: 35.2434\n",
      "Epoch 1192/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.2702 - val_loss: 35.6426\n",
      "Epoch 1193/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2985 - val_loss: 35.0962\n",
      "Epoch 1194/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.2751 - val_loss: 34.9477\n",
      "Epoch 1195/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 2.2622 - val_loss: 35.1019\n",
      "Epoch 1196/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2851 - val_loss: 35.1633\n",
      "Epoch 1197/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.2301 - val_loss: 35.2258\n",
      "Epoch 1198/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.2258 - val_loss: 34.9385\n",
      "Epoch 1199/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2312 - val_loss: 35.3010\n",
      "Epoch 1200/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.2612 - val_loss: 34.9765\n",
      "Epoch 1201/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2071 - val_loss: 35.2670\n",
      "Epoch 1202/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2257 - val_loss: 34.9771\n",
      "Epoch 1203/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1912 - val_loss: 35.2560\n",
      "Epoch 1204/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.2150 - val_loss: 35.3101\n",
      "Epoch 1205/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.2322 - val_loss: 35.1480\n",
      "Epoch 1206/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.2383 - val_loss: 35.0041\n",
      "Epoch 1207/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.2282 - val_loss: 35.1975\n",
      "Epoch 1208/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.2090 - val_loss: 35.2913\n",
      "Epoch 1209/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.1863 - val_loss: 34.9440\n",
      "Epoch 1210/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.1964 - val_loss: 35.1342\n",
      "Epoch 1211/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1919 - val_loss: 35.5079\n",
      "Epoch 1212/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1820 - val_loss: 35.3273\n",
      "Epoch 1213/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.1751 - val_loss: 35.1815\n",
      "Epoch 1214/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1677 - val_loss: 35.4030\n",
      "Epoch 1215/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1807 - val_loss: 35.0214\n",
      "Epoch 1216/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2122 - val_loss: 35.1224\n",
      "Epoch 1217/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2178 - val_loss: 35.2116\n",
      "Epoch 1218/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1922 - val_loss: 35.3700\n",
      "Epoch 1219/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1935 - val_loss: 35.1587\n",
      "Epoch 1220/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2432 - val_loss: 35.3510\n",
      "Epoch 1221/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1933 - val_loss: 35.2153\n",
      "Epoch 1222/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2131 - val_loss: 35.0946\n",
      "Epoch 1223/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1886 - val_loss: 35.1350\n",
      "Epoch 1224/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.1986 - val_loss: 35.2191\n",
      "Epoch 1225/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1639 - val_loss: 35.3716\n",
      "Epoch 1226/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.1527 - val_loss: 35.0576\n",
      "Epoch 1227/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.1607 - val_loss: 35.1379\n",
      "Epoch 1228/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.1458 - val_loss: 35.1595\n",
      "Epoch 1229/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.1620 - val_loss: 34.9630\n",
      "Epoch 1230/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1661 - val_loss: 35.2260\n",
      "Epoch 1231/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.1494 - val_loss: 35.2640\n",
      "Epoch 1232/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1360 - val_loss: 35.3101\n",
      "Epoch 1233/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1433 - val_loss: 35.1399\n",
      "Epoch 1234/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.1358 - val_loss: 35.2806\n",
      "Epoch 1235/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1661 - val_loss: 35.1749\n",
      "Epoch 1236/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1463 - val_loss: 35.1774\n",
      "Epoch 1237/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1780 - val_loss: 35.1786\n",
      "Epoch 1238/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.1499 - val_loss: 35.1409\n",
      "Epoch 1239/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.1523 - val_loss: 35.1731\n",
      "Epoch 1240/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1610 - val_loss: 35.2131\n",
      "Epoch 1241/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1494 - val_loss: 35.1557\n",
      "Epoch 1242/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.1686 - val_loss: 35.3681\n",
      "Epoch 1243/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1492 - val_loss: 35.2620\n",
      "Epoch 1244/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1452 - val_loss: 35.0804\n",
      "Epoch 1245/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1404 - val_loss: 35.1593\n",
      "Epoch 1246/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1501 - val_loss: 35.2060\n",
      "Epoch 1247/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1354 - val_loss: 35.2224\n",
      "Epoch 1248/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1397 - val_loss: 35.0403\n",
      "Epoch 1249/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.1474 - val_loss: 35.3545\n",
      "Epoch 1250/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1518 - val_loss: 35.1498\n",
      "Epoch 1251/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1333 - val_loss: 35.1165\n",
      "Epoch 1252/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1160 - val_loss: 35.1067\n",
      "Epoch 1253/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1252 - val_loss: 35.1394\n",
      "Epoch 1254/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1436 - val_loss: 35.3830\n",
      "Epoch 1255/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.1405 - val_loss: 35.2500\n",
      "Epoch 1256/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1273 - val_loss: 35.2319\n",
      "Epoch 1257/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1256 - val_loss: 35.0746\n",
      "Epoch 1258/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1681 - val_loss: 35.1704\n",
      "Epoch 1259/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1723 - val_loss: 35.3957\n",
      "Epoch 1260/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1634 - val_loss: 35.3564\n",
      "Epoch 1261/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1753 - val_loss: 35.2637\n",
      "Epoch 1262/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.1588 - val_loss: 35.1007\n",
      "Epoch 1263/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.1480 - val_loss: 35.0409\n",
      "Epoch 1264/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1330 - val_loss: 35.3931\n",
      "Epoch 1265/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1289 - val_loss: 35.3408\n",
      "Epoch 1266/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.1384 - val_loss: 35.1067\n",
      "Epoch 1267/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1496 - val_loss: 35.1104\n",
      "Epoch 1268/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1428 - val_loss: 35.1874\n",
      "Epoch 1269/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.1114 - val_loss: 35.3872\n",
      "Epoch 1270/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.1039 - val_loss: 35.3294\n",
      "Epoch 1271/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1222 - val_loss: 35.2964\n",
      "Epoch 1272/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0996 - val_loss: 35.2197\n",
      "Epoch 1273/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0954 - val_loss: 35.2664\n",
      "Epoch 1274/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.1299 - val_loss: 35.3773\n",
      "Epoch 1275/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1317 - val_loss: 35.0976\n",
      "Epoch 1276/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1124 - val_loss: 35.4306\n",
      "Epoch 1277/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1229 - val_loss: 35.3174\n",
      "Epoch 1278/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.1130 - val_loss: 35.2849\n",
      "Epoch 1279/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1068 - val_loss: 35.1508\n",
      "Epoch 1280/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1351 - val_loss: 35.1285\n",
      "Epoch 1281/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.1375 - val_loss: 35.2970\n",
      "Epoch 1282/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.1031 - val_loss: 35.1541\n",
      "Epoch 1283/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0973 - val_loss: 35.2262\n",
      "Epoch 1284/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0772 - val_loss: 35.1669\n",
      "Epoch 1285/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0901 - val_loss: 35.2929\n",
      "Epoch 1286/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0973 - val_loss: 35.1051\n",
      "Epoch 1287/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0831 - val_loss: 35.1527\n",
      "Epoch 1288/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0945 - val_loss: 35.1296\n",
      "Epoch 1289/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0960 - val_loss: 35.2316\n",
      "Epoch 1290/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0874 - val_loss: 35.1632\n",
      "Epoch 1291/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0882 - val_loss: 35.1586\n",
      "Epoch 1292/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1022 - val_loss: 35.2613\n",
      "Epoch 1293/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.1008 - val_loss: 35.0571\n",
      "Epoch 1294/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1032 - val_loss: 35.3712\n",
      "Epoch 1295/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.1120 - val_loss: 35.2492\n",
      "Epoch 1296/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.1137 - val_loss: 35.1259\n",
      "Epoch 1297/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0629 - val_loss: 35.0905\n",
      "Epoch 1298/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0959 - val_loss: 35.0143\n",
      "Epoch 1299/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0771 - val_loss: 35.0607\n",
      "Epoch 1300/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0912 - val_loss: 35.1473\n",
      "Epoch 1301/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0762 - val_loss: 35.1628\n",
      "Epoch 1302/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0879 - val_loss: 35.0690\n",
      "Epoch 1303/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0835 - val_loss: 35.0329\n",
      "Epoch 1304/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0703 - val_loss: 35.1474\n",
      "Epoch 1305/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0778 - val_loss: 35.1197\n",
      "Epoch 1306/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0656 - val_loss: 35.1388\n",
      "Epoch 1307/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0591 - val_loss: 35.0735\n",
      "Epoch 1308/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0521 - val_loss: 34.9766\n",
      "Epoch 1309/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0712 - val_loss: 35.2021\n",
      "Epoch 1310/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0996 - val_loss: 35.0586\n",
      "Epoch 1311/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.1082 - val_loss: 35.0456\n",
      "Epoch 1312/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0772 - val_loss: 35.1080\n",
      "Epoch 1313/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.0588 - val_loss: 34.9897\n",
      "Epoch 1314/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0762 - val_loss: 35.2905\n",
      "Epoch 1315/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0541 - val_loss: 34.9507\n",
      "Epoch 1316/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0667 - val_loss: 35.2429\n",
      "Epoch 1317/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0628 - val_loss: 35.2639\n",
      "Epoch 1318/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0647 - val_loss: 35.1434\n",
      "Epoch 1319/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1130 - val_loss: 35.2015\n",
      "Epoch 1320/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0613 - val_loss: 34.9003\n",
      "Epoch 1321/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0655 - val_loss: 35.2585\n",
      "Epoch 1322/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0530 - val_loss: 35.0895\n",
      "Epoch 1323/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0673 - val_loss: 35.0939\n",
      "Epoch 1324/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0703 - val_loss: 35.2752\n",
      "Epoch 1325/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0940 - val_loss: 35.0602\n",
      "Epoch 1326/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0810 - val_loss: 35.2757\n",
      "Epoch 1327/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0777 - val_loss: 35.2617\n",
      "Epoch 1328/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0776 - val_loss: 35.0486\n",
      "Epoch 1329/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0791 - val_loss: 35.1232\n",
      "Epoch 1330/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0718 - val_loss: 35.1005\n",
      "Epoch 1331/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0711 - val_loss: 35.0967\n",
      "Epoch 1332/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.0566 - val_loss: 35.1946\n",
      "Epoch 1333/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.0433 - val_loss: 35.1214\n",
      "Epoch 1334/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0479 - val_loss: 35.0547\n",
      "Epoch 1335/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0420 - val_loss: 35.2442\n",
      "Epoch 1336/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0586 - val_loss: 35.2150\n",
      "Epoch 1337/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0523 - val_loss: 35.1258\n",
      "Epoch 1338/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0467 - val_loss: 35.2017\n",
      "Epoch 1339/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0269 - val_loss: 35.2111\n",
      "Epoch 1340/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0300 - val_loss: 35.2717\n",
      "Epoch 1341/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0282 - val_loss: 35.1940\n",
      "Epoch 1342/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0203 - val_loss: 35.1371\n",
      "Epoch 1343/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0269 - val_loss: 35.1649\n",
      "Epoch 1344/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0494 - val_loss: 35.3857\n",
      "Epoch 1345/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0620 - val_loss: 35.0766\n",
      "Epoch 1346/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0390 - val_loss: 35.0629\n",
      "Epoch 1347/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0433 - val_loss: 35.0242\n",
      "Epoch 1348/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0220 - val_loss: 35.2177\n",
      "Epoch 1349/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0281 - val_loss: 35.1972\n",
      "Epoch 1350/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0308 - val_loss: 35.1101\n",
      "Epoch 1351/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0466 - val_loss: 35.2505\n",
      "Epoch 1352/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0544 - val_loss: 35.1569\n",
      "Epoch 1353/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0282 - val_loss: 35.2699\n",
      "Epoch 1354/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0431 - val_loss: 35.2104\n",
      "Epoch 1355/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0348 - val_loss: 35.0858\n",
      "Epoch 1356/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0410 - val_loss: 35.2383\n",
      "Epoch 1357/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0199 - val_loss: 35.0812\n",
      "Epoch 1358/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0244 - val_loss: 35.0665\n",
      "Epoch 1359/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0307 - val_loss: 35.0758\n",
      "Epoch 1360/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0518 - val_loss: 35.0926\n",
      "Epoch 1361/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0142 - val_loss: 35.1148\n",
      "Epoch 1362/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0194 - val_loss: 35.1373\n",
      "Epoch 1363/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0157 - val_loss: 35.1619\n",
      "Epoch 1364/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0232 - val_loss: 35.2604\n",
      "Epoch 1365/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0156 - val_loss: 34.9301\n",
      "Epoch 1366/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0307 - val_loss: 35.0834\n",
      "Epoch 1367/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0342 - val_loss: 35.1539\n",
      "Epoch 1368/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0049 - val_loss: 35.1120\n",
      "Epoch 1369/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0082 - val_loss: 35.1702\n",
      "Epoch 1370/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0034 - val_loss: 35.1486\n",
      "Epoch 1371/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0062 - val_loss: 35.1502\n",
      "Epoch 1372/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0086 - val_loss: 35.0388\n",
      "Epoch 1373/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.0350 - val_loss: 35.2162\n",
      "Epoch 1374/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.0370 - val_loss: 34.9388\n",
      "Epoch 1375/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0093 - val_loss: 35.2159\n",
      "Epoch 1376/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0315 - val_loss: 35.0960\n",
      "Epoch 1377/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.0205 - val_loss: 35.0249\n",
      "Epoch 1378/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.0173 - val_loss: 35.2655\n",
      "Epoch 1379/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9973 - val_loss: 35.1490\n",
      "Epoch 1380/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.0033 - val_loss: 35.2290\n",
      "Epoch 1381/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0087 - val_loss: 35.0920\n",
      "Epoch 1382/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.0005 - val_loss: 35.0900\n",
      "Epoch 1383/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9923 - val_loss: 35.0460\n",
      "Epoch 1384/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9896 - val_loss: 35.1309\n",
      "Epoch 1385/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.0047 - val_loss: 35.2024\n",
      "Epoch 1386/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.9943 - val_loss: 35.0959\n",
      "Epoch 1387/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.0005 - val_loss: 34.9907\n",
      "Epoch 1388/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0057 - val_loss: 35.1315\n",
      "Epoch 1389/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9915 - val_loss: 35.1813\n",
      "Epoch 1390/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9913 - val_loss: 35.0788\n",
      "Epoch 1391/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0002 - val_loss: 35.1699\n",
      "Epoch 1392/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0085 - val_loss: 35.1052\n",
      "Epoch 1393/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0084 - val_loss: 35.1212\n",
      "Epoch 1394/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9942 - val_loss: 35.1604\n",
      "Epoch 1395/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9952 - val_loss: 35.1305\n",
      "Epoch 1396/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9892 - val_loss: 35.1432\n",
      "Epoch 1397/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0048 - val_loss: 35.1516\n",
      "Epoch 1398/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0347 - val_loss: 35.0392\n",
      "Epoch 1399/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.0201 - val_loss: 35.1875\n",
      "Epoch 1400/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9892 - val_loss: 34.9695\n",
      "Epoch 1401/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9992 - val_loss: 35.1529\n",
      "Epoch 1402/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9917 - val_loss: 35.1824\n",
      "Epoch 1403/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9903 - val_loss: 35.0640\n",
      "Epoch 1404/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.9866 - val_loss: 35.1083\n",
      "Epoch 1405/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9825 - val_loss: 35.0865\n",
      "Epoch 1406/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9735 - val_loss: 35.1471\n",
      "Epoch 1407/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9884 - val_loss: 35.0928\n",
      "Epoch 1408/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9730 - val_loss: 35.0755\n",
      "Epoch 1409/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9862 - val_loss: 35.1548\n",
      "Epoch 1410/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.9745 - val_loss: 35.0376\n",
      "Epoch 1411/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9766 - val_loss: 35.1215\n",
      "Epoch 1412/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9791 - val_loss: 35.1118\n",
      "Epoch 1413/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9809 - val_loss: 35.1517\n",
      "Epoch 1414/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9821 - val_loss: 35.0524\n",
      "Epoch 1415/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9773 - val_loss: 35.0828\n",
      "Epoch 1416/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9683 - val_loss: 35.1146\n",
      "Epoch 1417/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9940 - val_loss: 35.1108\n",
      "Epoch 1418/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0141 - val_loss: 35.0527\n",
      "Epoch 1419/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9846 - val_loss: 35.0810\n",
      "Epoch 1420/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9680 - val_loss: 35.0766\n",
      "Epoch 1421/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9665 - val_loss: 35.1122\n",
      "Epoch 1422/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9741 - val_loss: 35.2152\n",
      "Epoch 1423/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9690 - val_loss: 35.1141\n",
      "Epoch 1424/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9651 - val_loss: 35.1183\n",
      "Epoch 1425/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9666 - val_loss: 35.1787\n",
      "Epoch 1426/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9660 - val_loss: 35.0731\n",
      "Epoch 1427/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9725 - val_loss: 35.0800\n",
      "Epoch 1428/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9772 - val_loss: 35.2014\n",
      "Epoch 1429/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9746 - val_loss: 35.1238\n",
      "Epoch 1430/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9906 - val_loss: 35.0621\n",
      "Epoch 1431/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9829 - val_loss: 35.1814\n",
      "Epoch 1432/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9566 - val_loss: 35.0674\n",
      "Epoch 1433/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9655 - val_loss: 35.0312\n",
      "Epoch 1434/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9608 - val_loss: 35.2247\n",
      "Epoch 1435/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9829 - val_loss: 35.0881\n",
      "Epoch 1436/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9585 - val_loss: 35.0979\n",
      "Epoch 1437/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9705 - val_loss: 35.1032\n",
      "Epoch 1438/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9597 - val_loss: 35.0755\n",
      "Epoch 1439/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9579 - val_loss: 35.0762\n",
      "Epoch 1440/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9621 - val_loss: 35.1612\n",
      "Epoch 1441/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9597 - val_loss: 35.1848\n",
      "Epoch 1442/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9565 - val_loss: 35.0854\n",
      "Epoch 1443/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9637 - val_loss: 35.1533\n",
      "Epoch 1444/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9555 - val_loss: 35.1141\n",
      "Epoch 1445/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9710 - val_loss: 35.0522\n",
      "Epoch 1446/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9611 - val_loss: 35.1844\n",
      "Epoch 1447/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9681 - val_loss: 35.0948\n",
      "Epoch 1448/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9512 - val_loss: 35.0687\n",
      "Epoch 1449/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9547 - val_loss: 35.1263\n",
      "Epoch 1450/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9474 - val_loss: 35.0578\n",
      "Epoch 1451/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9560 - val_loss: 35.1393\n",
      "Epoch 1452/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9548 - val_loss: 35.0397\n",
      "Epoch 1453/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9534 - val_loss: 35.1365\n",
      "Epoch 1454/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9398 - val_loss: 35.1279\n",
      "Epoch 1455/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9577 - val_loss: 35.0981\n",
      "Epoch 1456/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9510 - val_loss: 35.1389\n",
      "Epoch 1457/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9482 - val_loss: 35.1162\n",
      "Epoch 1458/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9572 - val_loss: 35.1554\n",
      "Epoch 1459/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9531 - val_loss: 35.1098\n",
      "Epoch 1460/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9491 - val_loss: 35.1424\n",
      "Epoch 1461/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9425 - val_loss: 35.0819\n",
      "Epoch 1462/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9383 - val_loss: 35.1538\n",
      "Epoch 1463/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9513 - val_loss: 35.0758\n",
      "Epoch 1464/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9406 - val_loss: 35.1040\n",
      "Epoch 1465/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9473 - val_loss: 35.1202\n",
      "Epoch 1466/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9387 - val_loss: 35.0945\n",
      "Epoch 1467/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9434 - val_loss: 35.0602\n",
      "Epoch 1468/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9411 - val_loss: 35.1070\n",
      "Epoch 1469/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9455 - val_loss: 35.0366\n",
      "Epoch 1470/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9521 - val_loss: 35.1027\n",
      "Epoch 1471/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9533 - val_loss: 35.1108\n",
      "Epoch 1472/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9415 - val_loss: 35.0239\n",
      "Epoch 1473/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9497 - val_loss: 35.0758\n",
      "Epoch 1474/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9476 - val_loss: 35.2196\n",
      "Epoch 1475/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9486 - val_loss: 35.0112\n",
      "Epoch 1476/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9360 - val_loss: 35.1058\n",
      "Epoch 1477/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9493 - val_loss: 35.1092\n",
      "Epoch 1478/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9504 - val_loss: 35.0429\n",
      "Epoch 1479/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9401 - val_loss: 35.1506\n",
      "Epoch 1480/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9384 - val_loss: 35.0772\n",
      "Epoch 1481/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9369 - val_loss: 35.0736\n",
      "Epoch 1482/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9379 - val_loss: 35.1047\n",
      "Epoch 1483/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9510 - val_loss: 35.1545\n",
      "Epoch 1484/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9332 - val_loss: 35.0376\n",
      "Epoch 1485/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9361 - val_loss: 35.0933\n",
      "Epoch 1486/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9397 - val_loss: 35.1355\n",
      "Epoch 1487/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9350 - val_loss: 35.1144\n",
      "Epoch 1488/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9385 - val_loss: 35.0991\n",
      "Epoch 1489/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.9335 - val_loss: 35.1332\n",
      "Epoch 1490/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.9357 - val_loss: 35.0670\n",
      "Epoch 1491/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9393 - val_loss: 35.1387\n",
      "Epoch 1492/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9267 - val_loss: 35.0389\n",
      "Epoch 1493/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9309 - val_loss: 35.0820\n",
      "Epoch 1494/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9301 - val_loss: 35.1060\n",
      "Epoch 1495/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9284 - val_loss: 35.0699\n",
      "Epoch 1496/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9346 - val_loss: 35.1111\n",
      "Epoch 1497/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9273 - val_loss: 35.0558\n",
      "Epoch 1498/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9244 - val_loss: 35.1114\n",
      "Epoch 1499/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9356 - val_loss: 35.0960\n",
      "Epoch 1500/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9255 - val_loss: 35.0656\n",
      "Epoch 1501/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9301 - val_loss: 35.0704\n",
      "Epoch 1502/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9302 - val_loss: 35.1182\n",
      "Epoch 1503/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9212 - val_loss: 35.0831\n",
      "Epoch 1504/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9213 - val_loss: 35.0771\n",
      "Epoch 1505/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9267 - val_loss: 35.0413\n",
      "Epoch 1506/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9210 - val_loss: 35.1023\n",
      "Epoch 1507/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9234 - val_loss: 35.0774\n",
      "Epoch 1508/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9161 - val_loss: 35.0746\n",
      "Epoch 1509/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9222 - val_loss: 35.1313\n",
      "Epoch 1510/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9284 - val_loss: 35.0996\n",
      "Epoch 1511/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9183 - val_loss: 35.1262\n",
      "Epoch 1512/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9236 - val_loss: 35.1281\n",
      "Epoch 1513/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9167 - val_loss: 35.0838\n",
      "Epoch 1514/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9234 - val_loss: 35.0701\n",
      "Epoch 1515/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9197 - val_loss: 35.0630\n",
      "Epoch 1516/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9183 - val_loss: 35.0452\n",
      "Epoch 1517/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9190 - val_loss: 35.0641\n",
      "Epoch 1518/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9182 - val_loss: 35.0956\n",
      "Epoch 1519/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9283 - val_loss: 35.0442\n",
      "Epoch 1520/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9210 - val_loss: 35.1457\n",
      "Epoch 1521/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9235 - val_loss: 35.0293\n",
      "Epoch 1522/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9259 - val_loss: 35.0918\n",
      "Epoch 1523/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9233 - val_loss: 35.0955\n",
      "Epoch 1524/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9239 - val_loss: 35.0998\n",
      "Epoch 1525/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9171 - val_loss: 35.0429\n",
      "Epoch 1526/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9194 - val_loss: 35.0767\n",
      "Epoch 1527/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9128 - val_loss: 35.0832\n",
      "Epoch 1528/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9143 - val_loss: 35.0478\n",
      "Epoch 1529/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9166 - val_loss: 35.0825\n",
      "Epoch 1530/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.9160 - val_loss: 35.0558\n",
      "Epoch 1531/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9180 - val_loss: 35.0937\n",
      "Epoch 1532/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.9150 - val_loss: 35.0481\n",
      "Epoch 1533/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.9131 - val_loss: 35.0552\n",
      "Epoch 1534/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9152 - val_loss: 35.0681\n",
      "Epoch 1535/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9128 - val_loss: 35.0451\n",
      "Epoch 1536/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.9103 - val_loss: 35.0410\n",
      "Epoch 1537/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9184 - val_loss: 35.0882\n",
      "Epoch 1538/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9139 - val_loss: 35.0616\n",
      "Epoch 1539/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.9127 - val_loss: 35.0678\n",
      "Epoch 1540/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9124 - val_loss: 35.0576\n",
      "Epoch 1541/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9125 - val_loss: 35.0992\n",
      "Epoch 1542/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9112 - val_loss: 35.0582\n",
      "Epoch 1543/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9108 - val_loss: 35.0737\n",
      "Epoch 1544/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9088 - val_loss: 35.0721\n",
      "Epoch 1545/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9139 - val_loss: 35.0434\n",
      "Epoch 1546/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9068 - val_loss: 35.0901\n",
      "Epoch 1547/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9062 - val_loss: 35.0683\n",
      "Epoch 1548/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.9106 - val_loss: 35.1127\n",
      "Epoch 1549/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9144 - val_loss: 35.0666\n",
      "Epoch 1550/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9154 - val_loss: 35.0795\n",
      "Epoch 1551/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9079 - val_loss: 35.0556\n",
      "Epoch 1552/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9070 - val_loss: 35.0939\n",
      "Epoch 1553/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9131 - val_loss: 35.1132\n",
      "Epoch 1554/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9100 - val_loss: 35.0881\n",
      "Epoch 1555/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9122 - val_loss: 35.0333\n",
      "Epoch 1556/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9070 - val_loss: 35.0862\n",
      "Epoch 1557/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9093 - val_loss: 35.0859\n",
      "Epoch 1558/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9093 - val_loss: 35.0813\n",
      "Epoch 1559/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.9061 - val_loss: 35.0646\n",
      "Epoch 1560/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9064 - val_loss: 35.0775\n",
      "Epoch 1561/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9087 - val_loss: 35.0883\n",
      "Epoch 1562/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9047 - val_loss: 35.0867\n",
      "Epoch 1563/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.9056 - val_loss: 35.0740\n",
      "Epoch 1564/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9042 - val_loss: 35.0777\n",
      "Epoch 1565/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9072 - val_loss: 35.0732\n",
      "Epoch 1566/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9043 - val_loss: 35.0847\n",
      "Epoch 1567/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9021 - val_loss: 35.1020\n",
      "Epoch 1568/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9046 - val_loss: 35.0969\n",
      "Epoch 1569/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9042 - val_loss: 35.0847\n",
      "Epoch 1570/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9021 - val_loss: 35.0548\n",
      "Epoch 1571/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9042 - val_loss: 35.0548\n",
      "Epoch 1572/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9033 - val_loss: 35.0675\n",
      "Epoch 1573/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9018 - val_loss: 35.0680\n",
      "Epoch 1574/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9056 - val_loss: 35.0964\n",
      "Epoch 1575/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9011 - val_loss: 35.0683\n",
      "Epoch 1576/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9020 - val_loss: 35.0666\n",
      "Epoch 1577/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9052 - val_loss: 35.0533\n",
      "Epoch 1578/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9017 - val_loss: 35.0774\n",
      "Epoch 1579/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9027 - val_loss: 35.0669\n",
      "Epoch 1580/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9001 - val_loss: 35.0874\n",
      "Epoch 1581/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9012 - val_loss: 35.0906\n",
      "Epoch 1582/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8995 - val_loss: 35.0663\n",
      "Epoch 1583/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9000 - val_loss: 35.0729\n",
      "Epoch 1584/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8997 - val_loss: 35.0640\n",
      "Epoch 1585/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.9000 - val_loss: 35.0720\n",
      "Epoch 1586/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8993 - val_loss: 35.0894\n",
      "Epoch 1587/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9002 - val_loss: 35.0799\n",
      "Epoch 1588/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8992 - val_loss: 35.0852\n",
      "Epoch 1589/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8990 - val_loss: 35.0932\n",
      "Epoch 1590/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9021 - val_loss: 35.0746\n",
      "Epoch 1591/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9001 - val_loss: 35.0965\n",
      "Epoch 1592/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9005 - val_loss: 35.0673\n",
      "Epoch 1593/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8992 - val_loss: 35.0752\n",
      "Epoch 1594/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8993 - val_loss: 35.0790\n",
      "Epoch 1595/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8985 - val_loss: 35.0609\n",
      "Epoch 1596/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9007 - val_loss: 35.0668\n",
      "Epoch 1597/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8984 - val_loss: 35.0717\n",
      "Epoch 1598/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8998 - val_loss: 35.0823\n",
      "Epoch 1599/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8977 - val_loss: 35.0771\n",
      "Epoch 1600/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8979 - val_loss: 35.0675\n",
      "Epoch 1601/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8988 - val_loss: 35.0708\n",
      "Epoch 1602/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8978 - val_loss: 35.0732\n",
      "Epoch 1603/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8967 - val_loss: 35.0965\n",
      "Epoch 1604/2000\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 1.8966 - val_loss: 35.0820\n",
      "Epoch 1605/2000\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.8957 - val_loss: 35.0789\n",
      "Epoch 1606/2000\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 1.8966 - val_loss: 35.0698\n",
      "Epoch 1607/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 1.8970 - val_loss: 35.0853\n",
      "Epoch 1608/2000\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 1.8980 - val_loss: 35.0720\n",
      "Epoch 1609/2000\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 1.8970 - val_loss: 35.0827\n",
      "Epoch 1610/2000\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 1.8963 - val_loss: 35.0786\n",
      "Epoch 1611/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8966 - val_loss: 35.0757\n",
      "Epoch 1612/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8957 - val_loss: 35.0670\n",
      "Epoch 1613/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8954 - val_loss: 35.0760\n",
      "Epoch 1614/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8968 - val_loss: 35.0745\n",
      "Epoch 1615/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8960 - val_loss: 35.0780\n",
      "Epoch 1616/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8978 - val_loss: 35.0867\n",
      "Epoch 1617/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8948 - val_loss: 35.0758\n",
      "Epoch 1618/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8960 - val_loss: 35.0852\n",
      "Epoch 1619/2000\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.8954 - val_loss: 35.0690\n",
      "Epoch 1620/2000\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 1.8939 - val_loss: 35.0750\n",
      "Epoch 1621/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 1.8954 - val_loss: 35.0850\n",
      "Epoch 1622/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8962 - val_loss: 35.0681\n",
      "Epoch 1623/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8941 - val_loss: 35.0647\n",
      "Epoch 1624/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8950 - val_loss: 35.0714\n",
      "Epoch 1625/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8941 - val_loss: 35.0710\n",
      "Epoch 1626/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8945 - val_loss: 35.0688\n",
      "Epoch 1627/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8952 - val_loss: 35.0674\n",
      "Epoch 1628/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8931 - val_loss: 35.0845\n",
      "Epoch 1629/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8935 - val_loss: 35.0852\n",
      "Epoch 1630/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8932 - val_loss: 35.0795\n",
      "Epoch 1631/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8935 - val_loss: 35.0780\n",
      "Epoch 1632/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.8930 - val_loss: 35.0735\n",
      "Epoch 1633/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8929 - val_loss: 35.0736\n",
      "Epoch 1634/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8946 - val_loss: 35.0853\n",
      "Epoch 1635/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8944 - val_loss: 35.0667\n",
      "Epoch 1636/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8935 - val_loss: 35.0707\n",
      "Epoch 1637/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8924 - val_loss: 35.0721\n",
      "Epoch 1638/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8932 - val_loss: 35.0735\n",
      "Epoch 1639/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8932 - val_loss: 35.0775\n",
      "Epoch 1640/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8925 - val_loss: 35.0809\n",
      "Epoch 1641/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8931 - val_loss: 35.0752\n",
      "Epoch 1642/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8922 - val_loss: 35.0751\n",
      "Epoch 1643/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8922 - val_loss: 35.0716\n",
      "Epoch 1644/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8926 - val_loss: 35.0752\n",
      "Epoch 1645/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8921 - val_loss: 35.0756\n",
      "Epoch 1646/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8923 - val_loss: 35.0757\n",
      "Epoch 1647/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8924 - val_loss: 35.0776\n",
      "Epoch 1648/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8920 - val_loss: 35.0775\n",
      "Epoch 1649/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8916 - val_loss: 35.0754\n",
      "Epoch 1650/2000\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.8921 - val_loss: 35.0728\n",
      "Epoch 1651/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 34ms/step - loss: 1.8922 - val_loss: 35.0769\n",
      "Epoch 1652/2000\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.8920 - val_loss: 35.0739\n",
      "Epoch 1653/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.8919 - val_loss: 35.0737\n",
      "Epoch 1654/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.8915 - val_loss: 35.0778\n",
      "Epoch 1655/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8920 - val_loss: 35.0844\n",
      "Epoch 1656/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 1.8913 - val_loss: 35.0799\n",
      "Epoch 1657/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8914 - val_loss: 35.0744\n",
      "Epoch 1658/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.8916 - val_loss: 35.0745\n",
      "Epoch 1659/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8914 - val_loss: 35.0789\n",
      "Epoch 1660/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8915 - val_loss: 35.0793\n",
      "Epoch 1661/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8915 - val_loss: 35.0786\n",
      "Epoch 1662/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8914 - val_loss: 35.0809\n",
      "Epoch 1663/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8911 - val_loss: 35.0802\n",
      "Epoch 1664/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8913 - val_loss: 35.0785\n",
      "Epoch 1665/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8909 - val_loss: 35.0770\n",
      "Epoch 1666/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8912 - val_loss: 35.0753\n",
      "Epoch 1667/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8911 - val_loss: 35.0774\n",
      "Epoch 1668/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8913 - val_loss: 35.0751\n",
      "Epoch 1669/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.8910 - val_loss: 35.0762\n",
      "Epoch 1670/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.8909 - val_loss: 35.0770\n",
      "Epoch 1671/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.8908 - val_loss: 35.0782\n",
      "Epoch 1672/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8910 - val_loss: 35.0767\n",
      "Epoch 1673/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8909 - val_loss: 35.0780\n",
      "Epoch 1674/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8909 - val_loss: 35.0768\n",
      "Epoch 1675/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8908 - val_loss: 35.0764\n",
      "Epoch 1676/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8909 - val_loss: 35.0783\n",
      "Epoch 1677/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8907 - val_loss: 35.0773\n",
      "Epoch 1678/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8907 - val_loss: 35.0771\n",
      "Epoch 1679/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8908 - val_loss: 35.0770\n",
      "Epoch 1680/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8906 - val_loss: 35.0772\n",
      "Epoch 1681/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8906 - val_loss: 35.0779\n",
      "Epoch 1682/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8907 - val_loss: 35.0775\n",
      "Epoch 1683/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8906 - val_loss: 35.0759\n",
      "Epoch 1684/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8906 - val_loss: 35.0772\n",
      "Epoch 1685/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8906 - val_loss: 35.0773\n",
      "Epoch 1686/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8906 - val_loss: 35.0768\n",
      "Epoch 1687/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8905 - val_loss: 35.0773\n",
      "Epoch 1688/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8905 - val_loss: 35.0771\n",
      "Epoch 1689/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8905 - val_loss: 35.0771\n",
      "Epoch 1690/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8904 - val_loss: 35.0769\n",
      "Epoch 1691/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8904 - val_loss: 35.0772\n",
      "Epoch 1692/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8904 - val_loss: 35.0772\n",
      "Epoch 1693/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8904 - val_loss: 35.0771\n",
      "Epoch 1694/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8904 - val_loss: 35.0770\n",
      "Epoch 1695/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8904 - val_loss: 35.0771\n",
      "Epoch 1696/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8904 - val_loss: 35.0773\n",
      "Epoch 1697/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8904 - val_loss: 35.0772\n",
      "Epoch 1698/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8903 - val_loss: 35.0771\n",
      "Epoch 1699/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8903 - val_loss: 35.0772\n",
      "Epoch 1700/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8903 - val_loss: 35.0771\n",
      "Epoch 1701/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8903 - val_loss: 35.0772\n",
      "Epoch 1702/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 1.8903 - val_loss: 35.0772\n",
      "Epoch 1703/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8903 - val_loss: 35.0772\n",
      "Epoch 1704/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.8903 - val_loss: 35.0772\n",
      "Epoch 1705/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8903 - val_loss: 35.0772\n",
      "Epoch 1706/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0955 - val_loss: 35.4968\n",
      "Epoch 1707/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2352 - val_loss: 34.8867\n",
      "Epoch 1708/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 2.3293 - val_loss: 35.0567\n",
      "Epoch 1709/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.4094 - val_loss: 35.8628\n",
      "Epoch 1710/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 2.3152 - val_loss: 35.3625\n",
      "Epoch 1711/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.3008 - val_loss: 34.9283\n",
      "Epoch 1712/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3495 - val_loss: 34.9666\n",
      "Epoch 1713/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.3391 - val_loss: 35.3015\n",
      "Epoch 1714/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0734 - val_loss: 34.8584\n",
      "Epoch 1715/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0307 - val_loss: 34.8432\n",
      "Epoch 1716/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 2.1152 - val_loss: 34.5948\n",
      "Epoch 1717/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1011 - val_loss: 34.6365\n",
      "Epoch 1718/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.1116 - val_loss: 35.4310\n",
      "Epoch 1719/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1461 - val_loss: 34.6229\n",
      "Epoch 1720/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.1025 - val_loss: 34.9130\n",
      "Epoch 1721/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.2752 - val_loss: 35.7266\n",
      "Epoch 1722/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2611 - val_loss: 35.0658\n",
      "Epoch 1723/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.3338 - val_loss: 35.4438\n",
      "Epoch 1724/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1317 - val_loss: 34.8221\n",
      "Epoch 1725/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0487 - val_loss: 35.2896\n",
      "Epoch 1726/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0376 - val_loss: 35.0477\n",
      "Epoch 1727/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1169 - val_loss: 34.7615\n",
      "Epoch 1728/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0443 - val_loss: 35.2235\n",
      "Epoch 1729/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0068 - val_loss: 35.2146\n",
      "Epoch 1730/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0996 - val_loss: 35.0323\n",
      "Epoch 1731/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0143 - val_loss: 35.2642\n",
      "Epoch 1732/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0213 - val_loss: 34.9048\n",
      "Epoch 1733/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0206 - val_loss: 35.1569\n",
      "Epoch 1734/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0583 - val_loss: 34.9666\n",
      "Epoch 1735/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0541 - val_loss: 35.3436\n",
      "Epoch 1736/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.1860 - val_loss: 34.7984\n",
      "Epoch 1737/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.1813 - val_loss: 35.3528\n",
      "Epoch 1738/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0850 - val_loss: 34.8073\n",
      "Epoch 1739/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0695 - val_loss: 35.3967\n",
      "Epoch 1740/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0788 - val_loss: 34.8653\n",
      "Epoch 1741/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1283 - val_loss: 34.7645\n",
      "Epoch 1742/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0418 - val_loss: 35.2457\n",
      "Epoch 1743/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0812 - val_loss: 35.0321\n",
      "Epoch 1744/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0736 - val_loss: 35.0741\n",
      "Epoch 1745/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0488 - val_loss: 35.1690\n",
      "Epoch 1746/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0517 - val_loss: 35.5163\n",
      "Epoch 1747/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 2.0388 - val_loss: 34.5086\n",
      "Epoch 1748/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0497 - val_loss: 35.1369\n",
      "Epoch 1749/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0037 - val_loss: 34.9065\n",
      "Epoch 1750/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0302 - val_loss: 34.7351\n",
      "Epoch 1751/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0348 - val_loss: 35.2601\n",
      "Epoch 1752/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 2.0902 - val_loss: 34.4720\n",
      "Epoch 1753/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.1994 - val_loss: 34.9911\n",
      "Epoch 1754/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0983 - val_loss: 35.0606\n",
      "Epoch 1755/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9992 - val_loss: 34.9422\n",
      "Epoch 1756/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9594 - val_loss: 35.1944\n",
      "Epoch 1757/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0041 - val_loss: 35.3467\n",
      "Epoch 1758/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.0132 - val_loss: 34.9244\n",
      "Epoch 1759/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0180 - val_loss: 35.0362\n",
      "Epoch 1760/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9620 - val_loss: 34.9169\n",
      "Epoch 1761/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9607 - val_loss: 35.1537\n",
      "Epoch 1762/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9636 - val_loss: 34.9968\n",
      "Epoch 1763/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9416 - val_loss: 35.0491\n",
      "Epoch 1764/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9904 - val_loss: 34.9510\n",
      "Epoch 1765/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0067 - val_loss: 34.9688\n",
      "Epoch 1766/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0441 - val_loss: 35.2459\n",
      "Epoch 1767/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9720 - val_loss: 35.0366\n",
      "Epoch 1768/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9792 - val_loss: 35.1416\n",
      "Epoch 1769/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9594 - val_loss: 34.7881\n",
      "Epoch 1770/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9614 - val_loss: 34.9925\n",
      "Epoch 1771/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9604 - val_loss: 34.9939\n",
      "Epoch 1772/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9123 - val_loss: 35.0225\n",
      "Epoch 1773/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9867 - val_loss: 34.8315\n",
      "Epoch 1774/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9069 - val_loss: 35.3714\n",
      "Epoch 1775/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9207 - val_loss: 34.8844\n",
      "Epoch 1776/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9024 - val_loss: 34.8457\n",
      "Epoch 1777/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9242 - val_loss: 35.0401\n",
      "Epoch 1778/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9894 - val_loss: 34.8922\n",
      "Epoch 1779/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9669 - val_loss: 35.3459\n",
      "Epoch 1780/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.9527 - val_loss: 34.9298\n",
      "Epoch 1781/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9466 - val_loss: 34.9919\n",
      "Epoch 1782/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9824 - val_loss: 35.0760\n",
      "Epoch 1783/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0453 - val_loss: 35.2225\n",
      "Epoch 1784/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9928 - val_loss: 35.0026\n",
      "Epoch 1785/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9648 - val_loss: 35.1392\n",
      "Epoch 1786/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9302 - val_loss: 35.0779\n",
      "Epoch 1787/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9600 - val_loss: 35.0637\n",
      "Epoch 1788/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9079 - val_loss: 35.4618\n",
      "Epoch 1789/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9456 - val_loss: 35.1612\n",
      "Epoch 1790/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9442 - val_loss: 35.2349\n",
      "Epoch 1791/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8871 - val_loss: 35.3040\n",
      "Epoch 1792/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9107 - val_loss: 34.9722\n",
      "Epoch 1793/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9803 - val_loss: 35.1465\n",
      "Epoch 1794/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8955 - val_loss: 35.3251\n",
      "Epoch 1795/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9508 - val_loss: 35.3574\n",
      "Epoch 1796/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8506 - val_loss: 35.1260\n",
      "Epoch 1797/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9145 - val_loss: 35.2855\n",
      "Epoch 1798/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8768 - val_loss: 35.1565\n",
      "Epoch 1799/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8881 - val_loss: 34.8941\n",
      "Epoch 1800/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9228 - val_loss: 35.1375\n",
      "Epoch 1801/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8973 - val_loss: 35.2869\n",
      "Epoch 1802/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8920 - val_loss: 34.8943\n",
      "Epoch 1803/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8871 - val_loss: 35.2998\n",
      "Epoch 1804/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9459 - val_loss: 35.1279\n",
      "Epoch 1805/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9636 - val_loss: 35.3067\n",
      "Epoch 1806/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.9916 - val_loss: 35.3448\n",
      "Epoch 1807/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0387 - val_loss: 35.7651\n",
      "Epoch 1808/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.0244 - val_loss: 35.1469\n",
      "Epoch 1809/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.0047 - val_loss: 35.4256\n",
      "Epoch 1810/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.0416 - val_loss: 35.4831\n",
      "Epoch 1811/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9274 - val_loss: 35.3326\n",
      "Epoch 1812/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.8823 - val_loss: 35.3998\n",
      "Epoch 1813/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.8983 - val_loss: 35.2444\n",
      "Epoch 1814/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9378 - val_loss: 35.1784\n",
      "Epoch 1815/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.0943 - val_loss: 35.4189\n",
      "Epoch 1816/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 2.0733 - val_loss: 35.5639\n",
      "Epoch 1817/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9565 - val_loss: 35.2877\n",
      "Epoch 1818/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8990 - val_loss: 35.7034\n",
      "Epoch 1819/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8412 - val_loss: 35.5670\n",
      "Epoch 1820/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8589 - val_loss: 35.3686\n",
      "Epoch 1821/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8708 - val_loss: 35.5900\n",
      "Epoch 1822/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8231 - val_loss: 35.5822\n",
      "Epoch 1823/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8484 - val_loss: 35.5838\n",
      "Epoch 1824/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8907 - val_loss: 35.3206\n",
      "Epoch 1825/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9395 - val_loss: 35.6119\n",
      "Epoch 1826/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8944 - val_loss: 35.6281\n",
      "Epoch 1827/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.8746 - val_loss: 35.5423\n",
      "Epoch 1828/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8983 - val_loss: 35.8044\n",
      "Epoch 1829/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9073 - val_loss: 35.2694\n",
      "Epoch 1830/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9647 - val_loss: 35.4986\n",
      "Epoch 1831/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8719 - val_loss: 35.9453\n",
      "Epoch 1832/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8797 - val_loss: 35.3524\n",
      "Epoch 1833/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.8665 - val_loss: 35.4909\n",
      "Epoch 1834/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8272 - val_loss: 35.4442\n",
      "Epoch 1835/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8434 - val_loss: 35.6425\n",
      "Epoch 1836/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.8261 - val_loss: 35.6140\n",
      "Epoch 1837/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8444 - val_loss: 35.6356\n",
      "Epoch 1838/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8365 - val_loss: 35.6661\n",
      "Epoch 1839/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.8554 - val_loss: 35.8669\n",
      "Epoch 1840/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8945 - val_loss: 35.5131\n",
      "Epoch 1841/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8472 - val_loss: 35.7906\n",
      "Epoch 1842/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8272 - val_loss: 35.5092\n",
      "Epoch 1843/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8505 - val_loss: 35.3311\n",
      "Epoch 1844/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8455 - val_loss: 35.7459\n",
      "Epoch 1845/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9086 - val_loss: 35.4998\n",
      "Epoch 1846/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8963 - val_loss: 35.7150\n",
      "Epoch 1847/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8482 - val_loss: 35.7732\n",
      "Epoch 1848/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9400 - val_loss: 36.0309\n",
      "Epoch 1849/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9165 - val_loss: 35.8200\n",
      "Epoch 1850/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8633 - val_loss: 35.2246\n",
      "Epoch 1851/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8349 - val_loss: 35.6320\n",
      "Epoch 1852/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8574 - val_loss: 35.4293\n",
      "Epoch 1853/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9038 - val_loss: 35.6467\n",
      "Epoch 1854/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8170 - val_loss: 35.7724\n",
      "Epoch 1855/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.8166 - val_loss: 35.6318\n",
      "Epoch 1856/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8493 - val_loss: 35.4695\n",
      "Epoch 1857/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9770 - val_loss: 35.6715\n",
      "Epoch 1858/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8683 - val_loss: 35.6854\n",
      "Epoch 1859/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8278 - val_loss: 35.6475\n",
      "Epoch 1860/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.7965 - val_loss: 35.6725\n",
      "Epoch 1861/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8347 - val_loss: 35.4704\n",
      "Epoch 1862/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8784 - val_loss: 36.1114\n",
      "Epoch 1863/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8403 - val_loss: 35.4024\n",
      "Epoch 1864/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8315 - val_loss: 36.1723\n",
      "Epoch 1865/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9182 - val_loss: 35.6985\n",
      "Epoch 1866/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9036 - val_loss: 35.5386\n",
      "Epoch 1867/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.9428 - val_loss: 35.7342\n",
      "Epoch 1868/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8223 - val_loss: 36.0194\n",
      "Epoch 1869/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8135 - val_loss: 35.5072\n",
      "Epoch 1870/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.7990 - val_loss: 35.9659\n",
      "Epoch 1871/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9185 - val_loss: 36.1570\n",
      "Epoch 1872/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8722 - val_loss: 36.1748\n",
      "Epoch 1873/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.0929 - val_loss: 36.0958\n",
      "Epoch 1874/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9783 - val_loss: 35.7063\n",
      "Epoch 1875/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9141 - val_loss: 35.6880\n",
      "Epoch 1876/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9491 - val_loss: 35.8263\n",
      "Epoch 1877/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8198 - val_loss: 36.1609\n",
      "Epoch 1878/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9056 - val_loss: 35.8818\n",
      "Epoch 1879/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9010 - val_loss: 35.7605\n",
      "Epoch 1880/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7967 - val_loss: 35.9009\n",
      "Epoch 1881/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8097 - val_loss: 35.9965\n",
      "Epoch 1882/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7943 - val_loss: 35.9306\n",
      "Epoch 1883/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7972 - val_loss: 36.3772\n",
      "Epoch 1884/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8599 - val_loss: 35.9156\n",
      "Epoch 1885/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 28ms/step - loss: 1.8551 - val_loss: 36.0801\n",
      "Epoch 1886/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7817 - val_loss: 35.9593\n",
      "Epoch 1887/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.7651 - val_loss: 36.2019\n",
      "Epoch 1888/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7856 - val_loss: 36.1828\n",
      "Epoch 1889/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7829 - val_loss: 36.0665\n",
      "Epoch 1890/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.7724 - val_loss: 36.0352\n",
      "Epoch 1891/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7497 - val_loss: 36.3992\n",
      "Epoch 1892/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8027 - val_loss: 36.0146\n",
      "Epoch 1893/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.7546 - val_loss: 36.0470\n",
      "Epoch 1894/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9219 - val_loss: 36.0454\n",
      "Epoch 1895/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8438 - val_loss: 36.1760\n",
      "Epoch 1896/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7946 - val_loss: 36.2050\n",
      "Epoch 1897/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8303 - val_loss: 35.9339\n",
      "Epoch 1898/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7878 - val_loss: 36.1883\n",
      "Epoch 1899/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8014 - val_loss: 36.2083\n",
      "Epoch 1900/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7933 - val_loss: 36.6301\n",
      "Epoch 1901/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7528 - val_loss: 36.4100\n",
      "Epoch 1902/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.7812 - val_loss: 36.0200\n",
      "Epoch 1903/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7183 - val_loss: 36.3838\n",
      "Epoch 1904/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7118 - val_loss: 36.0695\n",
      "Epoch 1905/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7582 - val_loss: 36.0375\n",
      "Epoch 1906/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.7771 - val_loss: 36.3597\n",
      "Epoch 1907/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7966 - val_loss: 36.5055\n",
      "Epoch 1908/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.7943 - val_loss: 36.4981\n",
      "Epoch 1909/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.7508 - val_loss: 36.3155\n",
      "Epoch 1910/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.7500 - val_loss: 36.3518\n",
      "Epoch 1911/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7577 - val_loss: 36.3286\n",
      "Epoch 1912/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.7536 - val_loss: 36.3288\n",
      "Epoch 1913/2000\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 1.7153 - val_loss: 36.3851\n",
      "Epoch 1914/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7571 - val_loss: 36.4465\n",
      "Epoch 1915/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7876 - val_loss: 36.2697\n",
      "Epoch 1916/2000\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 1.7644 - val_loss: 36.4619\n",
      "Epoch 1917/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7328 - val_loss: 36.7254\n",
      "Epoch 1918/2000\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.7587 - val_loss: 36.4752\n",
      "Epoch 1919/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7392 - val_loss: 36.3535\n",
      "Epoch 1920/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7600 - val_loss: 36.4138\n",
      "Epoch 1921/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7466 - val_loss: 36.5121\n",
      "Epoch 1922/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7745 - val_loss: 36.1975\n",
      "Epoch 1923/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7226 - val_loss: 36.3720\n",
      "Epoch 1924/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7187 - val_loss: 36.2868\n",
      "Epoch 1925/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7310 - val_loss: 36.2157\n",
      "Epoch 1926/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7211 - val_loss: 36.6313\n",
      "Epoch 1927/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7266 - val_loss: 36.2905\n",
      "Epoch 1928/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.7143 - val_loss: 36.4524\n",
      "Epoch 1929/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7590 - val_loss: 36.4504\n",
      "Epoch 1930/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7345 - val_loss: 36.5298\n",
      "Epoch 1931/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7379 - val_loss: 36.2158\n",
      "Epoch 1932/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7150 - val_loss: 36.5942\n",
      "Epoch 1933/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6991 - val_loss: 36.5567\n",
      "Epoch 1934/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6630 - val_loss: 36.2508\n",
      "Epoch 1935/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7249 - val_loss: 36.7306\n",
      "Epoch 1936/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7636 - val_loss: 36.4330\n",
      "Epoch 1937/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7880 - val_loss: 36.8768\n",
      "Epoch 1938/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7592 - val_loss: 36.7056\n",
      "Epoch 1939/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7826 - val_loss: 35.9635\n",
      "Epoch 1940/2000\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 1.7983 - val_loss: 37.0592\n",
      "Epoch 1941/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7324 - val_loss: 36.5545\n",
      "Epoch 1942/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7024 - val_loss: 36.6283\n",
      "Epoch 1943/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6740 - val_loss: 36.7132\n",
      "Epoch 1944/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6958 - val_loss: 36.6239\n",
      "Epoch 1945/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.6978 - val_loss: 36.5367\n",
      "Epoch 1946/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.6832 - val_loss: 36.6489\n",
      "Epoch 1947/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6904 - val_loss: 36.6720\n",
      "Epoch 1948/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.6998 - val_loss: 37.0384\n",
      "Epoch 1949/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.6940 - val_loss: 36.6295\n",
      "Epoch 1950/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.6497 - val_loss: 36.7565\n",
      "Epoch 1951/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7406 - val_loss: 37.0813\n",
      "Epoch 1952/2000\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.7459 - val_loss: 37.1091\n",
      "Epoch 1953/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7015 - val_loss: 36.5690\n",
      "Epoch 1954/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7768 - val_loss: 36.7151\n",
      "Epoch 1955/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6642 - val_loss: 37.1272\n",
      "Epoch 1956/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7290 - val_loss: 36.8241\n",
      "Epoch 1957/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7764 - val_loss: 36.6545\n",
      "Epoch 1958/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6915 - val_loss: 36.8745\n",
      "Epoch 1959/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7205 - val_loss: 36.8244\n",
      "Epoch 1960/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6957 - val_loss: 36.5359\n",
      "Epoch 1961/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6871 - val_loss: 36.7670\n",
      "Epoch 1962/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7174 - val_loss: 36.9009\n",
      "Epoch 1963/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7560 - val_loss: 37.0221\n",
      "Epoch 1964/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7351 - val_loss: 37.0784\n",
      "Epoch 1965/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.6720 - val_loss: 36.7525\n",
      "Epoch 1966/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6859 - val_loss: 36.9901\n",
      "Epoch 1967/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6475 - val_loss: 37.0270\n",
      "Epoch 1968/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7387 - val_loss: 37.0632\n",
      "Epoch 1969/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.6763 - val_loss: 36.7646\n",
      "Epoch 1970/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6862 - val_loss: 37.3547\n",
      "Epoch 1971/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.6700 - val_loss: 36.8084\n",
      "Epoch 1972/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.6621 - val_loss: 36.9310\n",
      "Epoch 1973/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7044 - val_loss: 36.7669\n",
      "Epoch 1974/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.6238 - val_loss: 37.0795\n",
      "Epoch 1975/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6510 - val_loss: 36.8063\n",
      "Epoch 1976/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.6494 - val_loss: 37.1602\n",
      "Epoch 1977/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.6779 - val_loss: 37.0788\n",
      "Epoch 1978/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6426 - val_loss: 37.1374\n",
      "Epoch 1979/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6659 - val_loss: 36.9671\n",
      "Epoch 1980/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7400 - val_loss: 37.0811\n",
      "Epoch 1981/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9978 - val_loss: 37.5633\n",
      "Epoch 1982/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.9236 - val_loss: 36.9743\n",
      "Epoch 1983/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 2.0411 - val_loss: 36.2652\n",
      "Epoch 1984/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.9323 - val_loss: 36.7318\n",
      "Epoch 1985/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8749 - val_loss: 36.2323\n",
      "Epoch 1986/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.8653 - val_loss: 37.3770\n",
      "Epoch 1987/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.8117 - val_loss: 36.4739\n",
      "Epoch 1988/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.6920 - val_loss: 36.7067\n",
      "Epoch 1989/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.7049 - val_loss: 36.7603\n",
      "Epoch 1990/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.6338 - val_loss: 36.7196\n",
      "Epoch 1991/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6658 - val_loss: 36.9942\n",
      "Epoch 1992/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.6454 - val_loss: 36.5972\n",
      "Epoch 1993/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.6617 - val_loss: 36.8059\n",
      "Epoch 1994/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7281 - val_loss: 36.5005\n",
      "Epoch 1995/2000\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.6223 - val_loss: 36.9110\n",
      "Epoch 1996/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6157 - val_loss: 37.0651\n",
      "Epoch 1997/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6411 - val_loss: 37.0120\n",
      "Epoch 1998/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.6558 - val_loss: 36.9443\n",
      "Epoch 1999/2000\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.7498 - val_loss: 36.8808\n",
      "Epoch 2000/2000\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.7880 - val_loss: 37.0297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./My Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./My Model\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001D7A3366C40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001D7A4B514C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "lr = CosineDecayRestarts(initial_learning_rate=0.001, first_decay_steps=20)\n",
    "my_model.compile(optimizer=Adam(lr), loss=MSE)\n",
    "\n",
    "cb = ModelCheckpoint('./Checkpoints/checkpoint', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "results = my_model.fit(x_train, y_train, batch_size=512, epochs=2000, callbacks=[cb], validation_data=(x_val, y_val))\n",
    "my_model.load_weights('./Checkpoints/checkpoint')\n",
    "my_model.save('./My Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ba161b",
   "metadata": {},
   "source": [
    "Evaluation of the process and results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a13e1a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 34.4720\n",
      "\n",
      "R2 score for train: 0.7416364168281242\n",
      "\n",
      "R2 score for validation: 0.24785179269280666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-5ebf350f8e84>:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  person_week2['data_usage_volume'] = final_person_data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R2 score for test: 0.5712503532605058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d7a3e65f40>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Test results:')\n",
    "my_model.evaluate(x_val, y_val)\n",
    "\n",
    "y_train_pred = my_model.predict(x_train)\n",
    "y_test_pred = my_model.predict(x_val)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.title('Losses')\n",
    "plt.legend(['Train Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_train)\n",
    "plt.plot(y_train_pred)\n",
    "plt.title('Train')\n",
    "plt.legend(['Actual Data', 'Predicted Values'])\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Usage Volume')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_val)\n",
    "plt.plot(y_test_pred)\n",
    "plt.title('Validation')\n",
    "plt.legend(['Actual Data', 'Predicted Values'])\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Usage Volume')\n",
    "\n",
    "r2_train = r2_score(y_true=y_train, y_pred=y_train_pred)\n",
    "print('\\nR2 score for train:', r2_train)\n",
    "\n",
    "r2_val = r2_score(y_true=y_val, y_pred=y_test_pred)\n",
    "print('\\nR2 score for validation:', r2_val)\n",
    "\n",
    "final_df = None\n",
    "for person in people:\n",
    "    person_train = train_file.loc[person]\n",
    "    person_week1 = week1_file.loc[person]\n",
    "    person_week2 = week2_file.loc[person]\n",
    "    days = person_week2.shape[0]\n",
    "    person_data = pd.concat([person_train, person_week1, person_week2]).drop('day', axis=1).values\n",
    "    data_dim = person_data.shape\n",
    "    for i in range(data_dim[0]):\n",
    "        for j in range(data_dim[1]):\n",
    "            if np.isnan(person_data[i, j]):\n",
    "                person_data[i, j] = np.nanmean(person_data[:, j])\n",
    "    for i in reversed(range(days)):\n",
    "        if i == 0:\n",
    "            sequence = person_data.copy()\n",
    "        else:\n",
    "            sequence = person_data.copy()[:-i]\n",
    "        sequence[:, -1] = np.roll(sequence[:, -1], 1, axis=0)\n",
    "        x = (sequence[1:] - x_min) / (x_max - x_min)\n",
    "        person_data[-i-1, -1] = float(my_model.predict(x[np.newaxis, :, :]))\n",
    "    final_person_data = person_data[-days:, -1]\n",
    "    person_week2.reset_index(level=0, inplace=True)\n",
    "    person_week2['data_usage_volume'] = final_person_data\n",
    "    person_df = person_week2[['day', 'subscriber_ecid', 'data_usage_volume']]\n",
    "    if final_df is None:\n",
    "        final_df = person_df\n",
    "    else:\n",
    "        final_df = pd.concat([final_df, person_df])\n",
    "\n",
    "pred = final_df['data_usage_volume'].values\n",
    "\n",
    "actual = pd.read_csv('./MCI-RD-aaic-UIUF/MCIRD_aaic2021_test_week2_with_target.csv')['data_usage_volume'].values\n",
    "\n",
    "r2_test = r2_score(y_true=actual, y_pred=pred)\n",
    "print('\\nR2 score for test:', r2_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(pred)\n",
    "plt.plot(actual)\n",
    "plt.title('Test')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Usage Volume')\n",
    "plt.legend(['Predicted Results', 'Actual Results'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa55b136",
   "metadata": {},
   "source": [
    "## Final results and creating the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ae04f84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "<ipython-input-33-cd2b3e486057>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  person_week3['data_usage_volume'] = final_person_data\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = './My Model'\n",
    "\n",
    "x_min = np.load(path + '/x_min.npy')\n",
    "x_max = np.load(path + '/x_max.npy')\n",
    "\n",
    "my_model = load_model(path)\n",
    "\n",
    "\n",
    "train_file = pd.read_csv('./MCI-RD-aaic-UIUF/MCIRD_aaic2021_train.csv', index_col='subscriber_ecid')\n",
    "train_file.insert(train_file.shape[1] - 1, 'data_usage_volume', train_file.pop('data_usage_volume'))\n",
    "\n",
    "week1_file = pd.read_csv('./MCI-RD-aaic-UIUF/MCIRD_aaic2021_test_week1_with_target.csv', index_col='subscriber_ecid')\n",
    "week1_file.insert(week1_file.shape[1] - 1, 'data_usage_volume', week1_file.pop('data_usage_volume'))\n",
    "\n",
    "week2_file = pd.read_csv('./MCI-RD-aaic-UIUF/MCIRD_aaic2021_test_week2_with_target.csv', index_col='subscriber_ecid')\n",
    "week2_file.insert(week2_file.shape[1] - 1, 'data_usage_volume', week2_file.pop('data_usage_volume'))\n",
    "\n",
    "week3_file = pd.read_csv('./MCI-RD-aaic-UIUF/MCIRD_aaic2021_test_week3.csv', index_col='subscriber_ecid')\n",
    "week3_file.insert(week3_file.shape[1], 'data_usage_volume', np.zeros(week3_file.shape[0]))\n",
    "\n",
    "people = np.unique(week3_file.index)\n",
    "\n",
    "final_df = None\n",
    "for person in people:\n",
    "    person_train = train_file.loc[person]\n",
    "    person_week1 = week1_file.loc[person]\n",
    "    person_week2 = week2_file.loc[person]\n",
    "    person_week3 = week3_file.loc[person]\n",
    "    days = person_week3.shape[0]\n",
    "    person_data = pd.concat([person_train, person_week1, person_week2, person_week3]).drop('day', axis=1).values\n",
    "    data_dim = person_data.shape\n",
    "    for i in range(data_dim[0]):\n",
    "        for j in range(data_dim[1]):\n",
    "            if np.isnan(person_data[i, j]):\n",
    "                person_data[i, j] = np.nanmean(person_data[:, j])\n",
    "    for i in reversed(range(days)):\n",
    "        if i == 0:\n",
    "            sequence = person_data.copy()\n",
    "        else:\n",
    "            sequence = person_data.copy()[:-i]\n",
    "        sequence[:, -1] = np.roll(sequence[:, -1], 1, axis=0)\n",
    "        x = (sequence[1:] - x_min) / (x_max - x_min)\n",
    "        person_data[-i-1, -1] = float(my_model.predict(x[np.newaxis, :, :]))\n",
    "    final_person_data = person_data[-days:, -1]\n",
    "    person_week3.reset_index(level=0, inplace=True)\n",
    "    person_week3['data_usage_volume'] = final_person_data\n",
    "    person_df = person_week3[['day', 'subscriber_ecid', 'data_usage_volume']]\n",
    "    if final_df is None:\n",
    "        final_df = person_df\n",
    "    else:\n",
    "        final_df = pd.concat([final_df, person_df])\n",
    "\n",
    "final_df.to_csv('./week3_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
